<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"vinyyang.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"giscus","storage":true,"lazyload":false,"nav":null,"activeClass":"giscus"},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="手撕论文知识库">
<meta property="og:type" content="article">
<meta property="og:title" content="手撕论文知识库">
<meta property="og:url" content="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/index.html">
<meta property="og:site_name" content="Viny与CS的邂逅">
<meta property="og:description" content="手撕论文知识库">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250219032451598.png">
<meta property="og:image" content="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250222212028325.png">
<meta property="og:image" content="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250222215408498.png">
<meta property="article:published_time" content="2025-02-18T18:38:36.000Z">
<meta property="article:modified_time" content="2025-02-24T17:19:07.553Z">
<meta property="article:author" content="Viny Yang">
<meta property="article:tag" content="科研知识积累">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250219032451598.png">


<link rel="canonical" href="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/","path":"手撕知识库/","title":"手撕论文知识库"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>手撕论文知识库 | Viny与CS的邂逅</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?7d748fca465d5b9edd218c485f0a2579"></script>






<script src="//sdk.jinrishici.com/v2/browser/jinrishici.js"></script>
<script>
  jinrishici.load((result) => {
    let jrsc = document.getElementById('jrsc');
    const data = result.data;
    let author = data.origin.author;
    let title = '《' + data.origin.title + '》';
    let content = data.content.substr(0, data.content.length - 1);
    let dynasty = data.origin.dynasty.substr(0, data.origin.dynasty.length - 1);
    jrsc.innerText = content + ' @ ' + dynasty + '·' + author + title;
  });
</script>
<div style="text-align: center"><span id="jrsc" >正在加载今日诗词....</span></div>
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Viny与CS的邂逅" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Viny与CS的邂逅</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">虽千万人吾往矣</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-guestbook"><a href="/guestbook/" rel="section"><i class="fa fa-book fa-fw"></i>留言板</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E7%9B%AE%E5%BD%95%E5%85%A8%E8%A7%88%E5%8F%8A%E8%A7%A3%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">深度学习项目代码目录全览及解析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88"><span class="nav-number">2.</span> <span class="nav-text">深度学习&#x2F;神经网络架构总览</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch"><span class="nav-number">3.</span> <span class="nav-text">PyTorch</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFtorch"><span class="nav-number">3.1.</span> <span class="nav-text">什么是torch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%92%8C%E5%8A%9F%E8%83%BD"><span class="nav-number">3.2.</span> <span class="nav-text">torch常用函数和功能</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F"><span class="nav-number">3.2.1.</span> <span class="nav-text">张量</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%BC%A0%E9%87%8F"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">什么是张量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9A%84%E7%BB%B4%E5%BA%A6"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">张量的维度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%BC%A0%E9%87%8F%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.1.3.</span> <span class="nav-text">张量相关函数</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC"><span class="nav-number">3.2.2.</span> <span class="nav-text">自动求导</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88Forward-Propagation%EF%BC%89"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">前向传播（Forward Propagation）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88Backward-Propagation%EF%BC%89"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">反向传播（Backward Propagation）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8E%E6%A2%AF%E5%BA%A6%E8%BF%BD%E8%B8%AA%EF%BC%88%E5%8F%AF%E7%95%A5%E8%BF%87%EF%BC%89"><span class="nav-number">3.2.2.3.</span> <span class="nav-text">计算图与梯度追踪（可略过）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E6%8E%A7%E5%88%B6%EF%BC%88%E5%8F%AF%E7%95%A5%E8%BF%87%EF%BC%89"><span class="nav-number">3.2.2.4.</span> <span class="nav-text">梯度控制（可略过）</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="nav-number">3.2.3.</span> <span class="nav-text">神经网络层</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E5%9F%BA%E7%B1%BB-nn-Module"><span class="nav-number">3.2.3.1.</span> <span class="nav-text">核心基类 nn.Module</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%A0%B8%E5%BF%83%E5%9F%BA%E7%B1%BB-nn-Module%EF%BC%9F"><span class="nav-number">3.2.3.1.1.</span> <span class="nav-text">什么是核心基类 nn.Module？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E7%BB%A7%E6%89%BF%E6%96%B9%E6%B3%95"><span class="nav-number">3.2.3.1.2.</span> <span class="nav-text">自定义模型继承方法</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%BD%91%E7%BB%9C%E5%B1%82-Layers"><span class="nav-number">3.2.3.2.</span> <span class="nav-text">网络层 (Layers)</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E5%B1%82"><span class="nav-number">3.2.3.2.1.</span> <span class="nav-text">基础层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="nav-number">3.2.3.2.2.</span> <span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%B1%82"><span class="nav-number">3.2.3.2.3.</span> <span class="nav-text">循环神经网络层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Transformer-%E7%9B%B8%E5%85%B3%E5%B1%82"><span class="nav-number">3.2.3.2.4.</span> <span class="nav-text">Transformer 相关层</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%BB%93%E6%9E%84%E5%8E%9F%E7%90%86"><span class="nav-number">3.2.4.</span> <span class="nav-text">多头注意力机制结构原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%A4%B4%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6"><span class="nav-number">3.2.5.</span> <span class="nav-text">多头自注意力机制</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82"><span class="nav-number">3.2.5.0.1.</span> <span class="nav-text">归一化层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.5.0.2.</span> <span class="nav-text">激活函数</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82"><span class="nav-number">3.2.5.0.3.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Dropout-%E5%B1%82"><span class="nav-number">3.2.5.0.4.</span> <span class="nav-text">Dropout 层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%B5%8C%E5%85%A5%E5%B1%82"><span class="nav-number">3.2.5.0.5.</span> <span class="nav-text">嵌入层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%A8%80%E7%96%8F%E5%B1%82"><span class="nav-number">3.2.5.0.6.</span> <span class="nav-text">稀疏层</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E8%A7%86%E8%A7%89%E4%B8%93%E7%94%A8%E5%B1%82"><span class="nav-number">3.2.5.0.7.</span> <span class="nav-text">视觉专用层</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%AE%B9%E5%99%A8"><span class="nav-number">3.2.5.1.</span> <span class="nav-text">模型容器</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E5%92%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.6.</span> <span class="nav-text">优化器和损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%EF%BC%88Optimizers%EF%BC%89"><span class="nav-number">3.2.6.1.</span> <span class="nav-text">优化器（Optimizers）</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E4%BC%98%E5%8C%96%E5%99%A8%EF%BC%9F"><span class="nav-number">3.2.6.1.1.</span> <span class="nav-text">什么是优化器？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E4%BC%98%E5%8C%96%E5%99%A8"><span class="nav-number">3.2.6.1.2.</span> <span class="nav-text">经典优化器</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E5%BA%A6"><span class="nav-number">3.2.6.1.3.</span> <span class="nav-text">学习率调度</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E8%A3%81%E5%89%AA"><span class="nav-number">3.2.6.1.4.</span> <span class="nav-text">梯度裁剪</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.6.2.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9F"><span class="nav-number">3.2.6.2.1.</span> <span class="nav-text">什么是损失函数？</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.2.6.2.2.</span> <span class="nav-text">分类任务</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%9B%9E%E5%BD%92%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.2.6.2.3.</span> <span class="nav-text">回归任务</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%94%9F%E6%88%90%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.2.6.2.4.</span> <span class="nav-text">生成任务</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%EF%BC%88torchvision-models%EF%BC%89%E4%B8%8E%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">3.2.7.</span> <span class="nav-text">预训练模型（torchvision.models）与迁移学习</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.7.1.</span> <span class="nav-text">计算机视觉模型</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8-CNN-%E6%9E%B6%E6%9E%84%EF%BC%88%E9%80%9A%E8%BF%87-torchvision-models%EF%BC%89"><span class="nav-number">3.2.7.1.1.</span> <span class="nav-text">经典 CNN 架构（通过 torchvision.models）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#Transformer-%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.7.1.2.</span> <span class="nav-text">Transformer 模型</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.2.7.2.</span> <span class="nav-text">自然语言处理模型</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88%E9%80%9A%E8%BF%87-transformers-%E5%BA%93%EF%BC%89"><span class="nav-number">3.2.7.2.1.</span> <span class="nav-text">预训练语言模型（通过 transformers 库）</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5"><span class="nav-number">3.2.7.3.</span> <span class="nav-text">迁移学习策略</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%EF%BC%88%E5%86%BB%E7%BB%93%E9%83%A8%E5%88%86%E5%B1%82%EF%BC%89"><span class="nav-number">3.2.7.3.1.</span> <span class="nav-text">特征提取（冻结部分层）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83%EF%BC%88Fine-tuning%EF%BC%89"><span class="nav-number">3.2.7.3.2.</span> <span class="nav-text">微调（Fine-tuning）</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E9%A2%84%E8%AE%AD%E7%BB%83%E7%89%B9%E5%BE%81%EF%BC%88%E5%A6%82-CLIP%EF%BC%89"><span class="nav-number">3.2.7.3.3.</span> <span class="nav-text">使用预训练特征（如 CLIP）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E7%AE%A1%E9%81%93-Data-Pipeline"><span class="nav-number">3.2.8.</span> <span class="nav-text">数据管道 (Data Pipeline)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB-Dataset"><span class="nav-number">3.2.8.1.</span> <span class="nav-text">数据集类 Dataset</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8-DataLoader"><span class="nav-number">3.2.8.2.</span> <span class="nav-text">数据加载器 DataLoader</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-torchvision-transforms"><span class="nav-number">3.2.8.3.</span> <span class="nav-text">数据增强&#96;&#96;torchvision.transforms&#96;</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96"><span class="nav-number">3.2.9.</span> <span class="nav-text">模型部署与性能优化</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#TorchScript-%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="nav-number">3.2.9.1.</span> <span class="nav-text">TorchScript 模型导出</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#ONNX-%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2"><span class="nav-number">3.2.9.2.</span> <span class="nav-text">ONNX 格式转换</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83-torch-cuda-amp"><span class="nav-number">3.2.9.3.</span> <span class="nav-text">混合精度训练 (torch.cuda.amp)</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#OS%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8E%A5%E5%8F%A3%E6%A8%A1%E5%9D%97"><span class="nav-number">4.</span> <span class="nav-text">OS操作系统接口模块</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Numpy"><span class="nav-number">5.</span> <span class="nav-text">Numpy</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Viny Yang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Viny Yang</p>
  <div class="site-description" itemprop="description">陌上花开，可缓缓归矣</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">4</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/VinyYang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;VinyYang" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/email.png" title="E-Mail → &#x2F;images&#x2F;email.png" rel="noopener me"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/wechat.png" title="Wechat → &#x2F;images&#x2F;wechat.png" rel="noopener me"><i class="fab fa-weixin fa-fw"></i>Wechat</a>
      </span>
      <span class="links-of-author-item">
        <a href="/images/qq.png" title="QQ → &#x2F;images&#x2F;qq.png" rel="noopener me"><i class="fab fa-qq fa-fw"></i>QQ</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://zhuanlan.zhihu.com/p/618864711" title="https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;618864711" rel="noopener" target="_blank">配置主题</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://zhuanlan.zhihu.com/p/671308695" title="https:&#x2F;&#x2F;zhuanlan.zhihu.com&#x2F;p&#x2F;671308695" rel="noopener" target="_blank">重新部署</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://copilot.github.com/" title="https:&#x2F;&#x2F;copilot.github.com&#x2F;" rel="noopener" target="_blank">Copilot</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://chat.deepseek.com/" title="https:&#x2F;&#x2F;chat.deepseek.com&#x2F;" rel="noopener" target="_blank">DeepSeek</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://chatgpt.com/" title="https:&#x2F;&#x2F;chatgpt.com&#x2F;" rel="noopener" target="_blank">ChatGPT</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Viny Yang">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Viny与CS的邂逅">
      <meta itemprop="description" content="陌上花开，可缓缓归矣">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="手撕论文知识库 | Viny与CS的邂逅">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          手撕论文知识库
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-19 02:38:36" itemprop="dateCreated datePublished" datetime="2025-02-19T02:38:36+08:00">2025-02-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-02-25 01:19:07" itemprop="dateModified" datetime="2025-02-25T01:19:07+08:00">2025-02-25</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%A7%91%E7%A0%94/" itemprop="url" rel="index"><span itemprop="name">科研</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
  <div style="padding-left: 8px;">
    <span class="post-meta-divider" style="padding-right: 8px;">|</span>
    <i class="fa fa-thumbtack"></i>
    <font color=purple style="font-weight: bold; padding-left: 4px;"> 置顶 </font>
  </div>


    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>50k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>1:30</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>手撕论文知识库</p>
<h2 id="深度学习项目代码目录全览及解析"><a href="#深度学习项目代码目录全览及解析" class="headerlink" title="深度学习项目代码目录全览及解析"></a>深度学习项目代码目录全览及解析</h2><blockquote>
<p>常见目录如下：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">project_name/</span><br><span class="line">├── data/                   # 数据集相关（原始/处理后的数据）</span><br><span class="line">├── dataloader/             # 数据加载与预处理模块（核心）</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── dataset.py          # 自定义Dataset类</span><br><span class="line">│   └── transforms.py       # 数据增强操作</span><br><span class="line">├── models/                 # 模型定义（核心）</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── backbone.py         # 主干网络</span><br><span class="line">│   └── layers.py           # 自定义网络层</span><br><span class="line">├── configs/                # 超参数配置文件（如YAML/JSON）</span><br><span class="line">├── utils/                  # 工具函数（如日志、评估指标）</span><br><span class="line">│   ├── data_utils.py</span><br><span class="line">│   ├── model_utils.py</span><br><span class="line">│   ├── visualization_utils.py</span><br><span class="line">│   └──...</span><br><span class="line">├── logs/                   # 记录训练和评估过程中的日志信息</span><br><span class="line">│   ├── training.log</span><br><span class="line">│   ├── validation.log</span><br><span class="line">│   └──...</span><br><span class="line">├── checkpoints/            # 训练保存的模型权重</span><br><span class="line">├── scripts/                # 运行脚本（训练/测试命令）</span><br><span class="line">├── requirements.txt        # 依赖库列表</span><br><span class="line">├── environment.yml         # Conda环境配置</span><br><span class="line">├── README.md               # 项目说明</span><br><span class="line">└── main.py                 # 主程序入口</span><br></pre></td></tr></table></figure>

<blockquote>
<ol>
<li><code>dataloader/</code></li>
</ol>
<p> <strong>作用</strong>：数据加载、预处理、增强（如论文项目中的 <code>with_colmap.py</code> 可能与多视图数据对齐相关）</p>
<p> <strong>典型内容</strong>：<code>Dataset</code> 类定义、数据增强函数、特征提取工具（如项目中的 <code>with_feature.py</code>）</p>
<ol start="2">
<li><strong><code>models/</code></strong></li>
</ol>
<p> <strong>作用</strong>：定义神经网络模型（如项目中的<code>nerf_models.py</code> 可实现NeRF的核心架构）。</p>
<p> <strong>典型内容</strong>：模型类继承<code>torch.nn.Module</code>，包含前向传播逻辑（如项目中的<code>depth_decoder.py</code>可用于深度估计解码）。</p>
<ol start="3">
<li><strong><code>utils/</code></strong></li>
</ol>
<p> <strong>作用</strong>：辅助工具（如项目中的 <code>pose_utils.py</code> 处理相机位姿，<code>training_utils.py</code> 封装训练逻辑）。</p>
<p> <strong>典型内容</strong>：评估指标计算、可视化工具、训练回调函数。</p>
<ol start="4">
<li><strong><code>third_party/</code></strong></li>
</ol>
<p> <strong>作用</strong>：第三方库或工具（如项目中的 <code>ATE</code> 可能用于轨迹评估，<code>pytorch_ssim</code> 实现结构相似性损失）。</p>
<ol start="5">
<li>其他关键要素</li>
</ol>
<p> <code>logs</code> 文件夹：记录训练和评估过程中的日志信息，如训练损失、验证损失、准确率等指标的变化情况，便于跟踪模型训练过程，分析模型的收敛性和性能表现。</p>
<p> <code>checkpoints</code> 文件夹：保存训练过程中的模型检查点，即模型在不同训练阶段的参数文件，用于在训练中断时恢复训练，或者用于选择在验证集上表现最好的模型进行测试和部署。</p>
<p> <code>requirement.txt</code>：列出项目所需的 Python 依赖库及其版本号，便于在新环境中快速安装项目所需的所有依赖。</p>
<p> <code>environment.yml</code>：Conda环境配置，确保依赖一致性。</p>
<p> <code>README.md</code>：项目说明、安装与使用指南（深度学习项目必备）。</p>
<p> <strong><code>main.py</code></strong>：项目的主程序入口，通常包含模型训练、评估和预测的主要逻辑，可通过命令行参数来控制程序的运行方式和参数设置。</p>
</blockquote>
<blockquote>
<p>示例如下：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">occ - nerf/  # 基于占用率的神经辐射场项目根目录</span><br><span class="line">├──.gitignore  # 指定Git不跟踪的文件或文件夹</span><br><span class="line">├── LICENSE  # 项目使用许可条款文件</span><br><span class="line">├── README.md  # 介绍项目背景、功能、使用方法等的说明文档</span><br><span class="line">├── environment.yml  # 定义项目运行所需软件环境</span><br><span class="line">├── local1.txt  # 用途不明，或为本地说明、配置等文件</span><br><span class="line">├── dataloader/  # 存放数据加载与预处理代码</span><br><span class="line">│   ├── any_folder.py  # 从任意文件夹结构加载数据</span><br><span class="line">│   ├── local_save.py  # 负责数据本地保存</span><br><span class="line">│   ├── with_colmap.py  # 从COLMAP处理后格式加载数据</span><br><span class="line">│   ├── with_feature.py  # 加载带特征的数据</span><br><span class="line">│   ├── with_feature_colmap.py  # 结合COLMAP与特征数据加载</span><br><span class="line">│   └── with_mask.py  # 加载带掩码的数据</span><br><span class="line">├── models/  # 存放深度学习模型定义与操作代码</span><br><span class="line">│   ├── depth_decoder.py  # 深度解码，用于深度估计</span><br><span class="line">│   ├── intrinsics.py  # 处理相机内参相关内容</span><br><span class="line">│   ├── layers.py  # 定义深度学习层结构</span><br><span class="line">│   ├── nerf_feature.py  # 处理NeRF特征相关逻辑</span><br><span class="line">│   ├── nerf_mask.py  # 处理NeRF模型中掩码相关内容</span><br><span class="line">│   ├── nerf_models.py  # 定义NeRF模型架构等核心内容</span><br><span class="line">│   └── poses.py  # 处理位姿相关操作</span><br><span class="line">├── utils/  # 包含辅助项目运行的工具函数</span><br><span class="line">│   ├── align_traj.py  # 实现轨迹对齐算法</span><br><span class="line">│   ├── comp_ate.py  # 计算绝对轨迹误差</span><br><span class="line">│   ├── comp_ray_dir.py  # 计算光线方向</span><br><span class="line">│   ├── lie_group_helper.py  # 提供李群相关辅助函数</span><br><span class="line">│   ├── pos_enc.py  # 实现位置编码</span><br><span class="line">│   ├── pose_utils.py  # 提供位姿相关实用工具函数</span><br><span class="line">│   ├── split_dataset.py  # 划分数据集为训练、验证、测试集</span><br><span class="line">│   ├── training_utils.py  # 提供模型训练辅助函数</span><br><span class="line">│   ├── vgg.py  # 与VGG神经网络相关操作</span><br><span class="line">│   ├── vis_cam_traj.py  # 可视化相机轨迹</span><br><span class="line">│   └── volume_op.py  # 操作三维体数据</span><br><span class="line">├── tasks/  # 存放训练、测试等具体任务代码</span><br><span class="line">│   └──...</span><br><span class="line">└── third_party/  # 存放第三方代码或库</span><br><span class="line">    ├── ATE/  # 与绝对轨迹误差计算相关</span><br><span class="line">    │   └── README.md  # 说明该部分功能与用法</span><br><span class="line">    └── pytorch_ssim/  # 计算结构相似性指数的库</span><br></pre></td></tr></table></figure>

<h2 id="深度学习-神经网络架构总览"><a href="#深度学习-神经网络架构总览" class="headerlink" title="深度学习&#x2F;神经网络架构总览"></a>深度学习&#x2F;神经网络架构总览</h2><h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><h3 id="什么是torch"><a href="#什么是torch" class="headerlink" title="什么是torch"></a>什么是torch</h3><p>Torch 是 PyTorch 深度学习框架的核心库，具备强大的功能与广泛的用途。它提供了丰富的张量操作，可在 CPU 或 GPU 上高效计算，能轻松处理各类数据；其自动求导机制极大简化了深度学习中梯度计算与反向传播的过程，让模型训练更为便捷。借助<code>torch.nn</code>模块可方便构建如 CNN、RNN 等复杂神经网络架构，<code>torch.optim</code>模块提供多种优化算法用于模型参数更新。此外，Torch 还支持预训练模型的使用与微调，结合可视化工具能助力监控训练过程，广泛应用于图像、自然语言处理、推荐系统等诸多领域。</p>
<h3 id="torch常用函数和功能"><a href="#torch常用函数和功能" class="headerlink" title="torch常用函数和功能"></a>torch常用函数和功能</h3><h4 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h4><h5 id="什么是张量"><a href="#什么是张量" class="headerlink" title="什么是张量"></a>什么是张量</h5><p>张量是多维数组的泛化表示，可理解为一个多维的数据容器，零维张量是标量，一维张量是向量，二维张量是矩阵，三维及以上则是更高阶的张量。在深度学习里，使用张量是因为它能够高效地表示和处理大量的数据，像图像可表示为三维张量（高度、宽度、通道数），视频可表示为四维张量（帧数、高度、宽度、通道数）。并且，深度学习框架（如 PyTorch）针对张量运算进行了高度优化，能利用 GPU 等硬件加速计算，张量还能自然地支持自动求导机制，方便进行模型训练时的梯度计算和参数更新。</p>
<p>张量是 PyTorch 中最基础的数据结构，类似于 NumPy 的多维数组，但它可以在 GPU 上进行加速计算，并且支持自动求导等深度学习所需的特性。</p>
<h5 id="张量的维度"><a href="#张量的维度" class="headerlink" title="张量的维度"></a>张量的维度</h5><p>维度（也称为轴）是指张量在某个方向上的延伸。可以将维度理解为数据组织的一个方向或一个层次，类似于在地理坐标系统中，经度和纬度分别代表了不同的方向，张量的每个维度也代表了数据的一个特定方向的排列。维度的数量被称为张量的阶（rank），零阶张量是标量（一个单独的数值），一阶张量是向量（一维数组），二阶张量是矩阵（二维数组），三阶及以上的张量则用于表示更复杂的数据结构。</p>
<p><strong>注：维度从0开始算起，比如对于二阶张量，维度0代表行，维度1代表列</strong></p>
<p><strong>另：维度排列遵循（$a_n$, $a_{n-1}$, …, $a_1$）的形式，数字越前代表越高维的堆叠。比如<code>torch.zeros((2, 3, 4, 5))</code>，那就是两个三维（三层）的4x5矩阵叠在一起</strong></p>
<p><strong>1.零阶张量（标量）</strong></p>
<p>零阶张量只有一个数值，它没有方向的概念，维度数量为 0。例如这里的 <code>scalar</code> 就是一个零阶张量，它代表一个单一的数值，不涉及方向或多个元素的排列。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">scalar = torch.tensor(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;标量的维度数量:&quot;</span>, scalar.dim()) </span><br></pre></td></tr></table></figure>

<p><strong>2.一阶张量（向量）</strong></p>
<p>一阶张量可以看作是一个向量，它有一个维度。这个维度代表了向量中元素的排列方向，向量的长度就是这个维度的大小。例如<code>vector</code> 是一个一阶张量，维度数量为 1，该维度的大小为 4，表示向量中有 4 个元素。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vector = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量的维度数量:&quot;</span>, vector.dim()) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;向量在该维度的大小:&quot;</span>, vector.size(<span class="number">0</span>)) </span><br></pre></td></tr></table></figure>

<p><strong>3.二阶张量（矩阵）</strong></p>
<p>二阶张量是一个矩阵，有两个维度，通常称为行和列。第一个维度代表矩阵的行方向，第二个维度代表矩阵的列方向。例如<code>matrix</code> 是一个 2 行 3 列的矩阵，第一个维度的大小为 2 表示有 2 行，第二个维度的大小为 3 表示有 3 列。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">matrix = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵的维度数量:&quot;</span>, matrix.dim()) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵第一个维度（行）的大小:&quot;</span>, matrix.size(<span class="number">0</span>)) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵第二个维度（列）的大小:&quot;</span>, matrix.size(<span class="number">1</span>)) </span><br></pre></td></tr></table></figure>

<p><strong>4.高阶张量（图像、视频等）</strong></p>
<p>对于三阶及以上的张量，维度的含义更加丰富，通常与具体的数据类型和应用场景相关。</p>
<p><strong>图像数据</strong>：在处理图像时，通常使用三阶张量。例如，一张彩色图像可以表示为一个形状为 <code>(高度, 宽度, 通道数)</code> 的三阶张量。这里的第一个维度代表图像的高度方向，第二个维度代表图像的宽度方向，第三个维度代表图像的通道（如 RGB 三个通道）。</p>
<p><code>image = torch.randn(224, 224, 3)</code> 这行代码能够随机生成一个形状为 <code>(224, 224, 3)</code> 的张量来模拟图像的三通道数值。</p>
<p>由于 <code>torch.randn()</code> 生成的是服从标准正态分布的随机数，这些数值可能为负数，也可能超出了常见图像像素值的范围（通常是 0 - 255 或者 0 - 1）。在实际的图像处理任务中，如果需要模拟真实图像，可能需要对这些随机值进行进一步的处理，例如通过归一化或裁剪操作将其限制在合适的范围内。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">image = torch.randn(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;图像张量的维度数量:&quot;</span>, image.dim()) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;图像高度维度的大小:&quot;</span>, image.size(<span class="number">0</span>)) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;图像宽度维度的大小:&quot;</span>, image.size(<span class="number">1</span>)) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;图像通道维度的大小:&quot;</span>, image.size(<span class="number">2</span>)) </span><br></pre></td></tr></table></figure>

<p><img src="/./%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250219032451598.png" alt="image-20250219032451598"></p>
<p><strong>视频数据</strong>：视频可以看作是一系列的图像帧，因此可以用四阶张量表示，形状通常为 <code>(帧数, 高度, 宽度, 通道数)</code>。第一个维度代表视频中的帧数，其余维度与图像张量的含义相同。</p>
<p>*<strong>5.通道</strong></p>
<p>通道指图像中特定类型信息的集合，图像可含一个或多个通道，各通道存储图像某方面特征数据。像单通道存亮度，RGB 三通道分别存红、绿、蓝颜色信息，四通道还多了透明度通道，以此组合完整呈现图像。</p>
<p>通道能实现颜色表示与混合，如 RGB 三通道通过不同数值组合呈现丰富色彩；可用于特征提取与分析，不同通道提供不同特征，助力图像分析和目标识别；还能用于图像合成与特效制作，借助透明度通道可控制图像透明效果实现合成。</p>
<p>在图片里，灰度图用单通道呈现黑白影像；彩色照片靠 RGB 三通道展示多彩画面；PNG 图片利用四通道含透明度信息实现图像融合。视频是连续的图片帧，同样利用通道来呈现色彩、进行特效处理，如影视中常见的抠图合成场景就借助了通道特性。</p>
<h5 id="张量相关函数"><a href="#张量相关函数" class="headerlink" title="张量相关函数"></a>张量相关函数</h5><p><strong>1.创建</strong></p>
<ul>
<li><p>创建张量<code>torch.tensor()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">tensor = torch.tensor(data)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>当你有现有的数据存储在 Python 列表或 NumPy 数组中，并且需要将其输入到 PyTorch 模型进行计算时使用。例如，在加载数据集后，将数据转换为张量形式以便后续处理。</p>
<p>从数据存储的角度来看，<code>tensor</code> 存储了 Python 列表 <code>data</code> 中的元素 <code>[1, 2, 3]</code>。它将这些数据以一种高效的、适合计算机处理的方式组织起来，存储在内存中。在这个例子中，<code>tensor</code> 是一个一维张量，形状为 <code>(3,)</code>，这意味着它包含 3 个元素。</p>
<p>在数学运算方面，<code>tensor</code> 可以参与各种数学运算，如加法、乘法、矩阵乘法等。PyTorch 为张量提供了丰富的数学运算函数，这些运算可以在 CPU 或 GPU 上高效执行。</p>
<p>在深度学习的上下文中，<code>tensor</code> 是模型输入、输出以及参数的基本表示形式。例如，在一个简单的全连接神经网络中，输入数据会被转换为张量输入到网络中，网络的权重和偏置也是以张量的形式存储和更新的。在上述例子中，<code>tensor</code> 可以作为一个简单的输入数据示例，如果要构建一个神经网络处理这个输入，可能会进行如下操作（以下是一个简单示例）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个简单的全连接层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)  <span class="comment"># 输入维度为 3，输出维度为 1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备输入数据</span></span><br><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(<span class="number">0</span>)  <span class="comment"># 转换为适合输入模型的形状</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output = model(tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型输出:&quot;</span>, output)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>创建全零张量<code>torch.zeros()</code></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zeros_tensor = torch.zeros((<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
<p>常用于初始化某些变量，如在初始化神经网络的偏置项时，可使用全零张量。另外，在需要填充零值进行数据预处理或占位时也会用到。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">创建的全零张量：</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line">张量的形状： torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<p>传入的参数 <code>(2, 3)</code>对应创建的 <code>zeros_tensor</code> 是一个 2 行 3 列的二维张量。如果使用 <code>torch.zeros((2, 3, 4))</code> 这样的代码，那么创建的就是一个三维张量，其中 <code>2</code> 表示最外层维度的大小（可以想象成有 2 个二维矩阵堆叠在一起），<code>3</code> 表示每个二维矩阵的行数，<code>4</code> 表示每个二维矩阵的列数。依此类推，对于更高维的张量，每个数字都代表对应维度上的大小。相当于高是2，行是3，列是4</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">创建的全零张量：</span><br><span class="line">tensor([[[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]],</span><br><span class="line"></span><br><span class="line">        [[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">         [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]]])</span><br><span class="line">张量的形状： torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br></pre></td></tr></table></figure>

<p>如果是<code>torch.zeros((2, 3, 4, 5))</code>，那就是两个三维（三层）的4x5矩阵叠在一起，数字越前就代表越高维的堆叠。</p>
<ul>
<li><p>创建全一张量**<code>torch.ones()</code>**</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ones_tensor = torch.ones((<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
<p>与 <code>torch.zeros()</code> 类似，可用于初始化特定变量。在一些归一化操作或需要特定初始值为 1 的场景中会使用。</p>
<ul>
<li><p>创建指定形状的随机张量，元素值在[0 , 1)之间**<code>torch.rand()</code>**</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_tensor = torch.rand((<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></li>
</ul>
<p>在初始化神经网络的权重时，随机初始化是常见的做法，可使用 <code>torch.rand()</code> 生成初始权重张量。</p>
<p><strong>2.操作</strong></p>
<ul>
<li><p><strong><code>torch.cat()</code></strong>：用于在指定维度上拼接多个张量。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">b = torch.tensor([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">c = torch.cat((a, b), dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>当需要将多个张量合并为一个更大的张量时使用。例如，在处理多模态数据时，将不同模态的特征张量拼接在一起。</p>
<p><code>torch.cat((a, b), dim=1)</code> 表示在维度 1（列方向）上对张量 <code>a</code> 和 <code>b</code> 进行拼接。可以看到，拼接后的张量 <code>c</code> 是将 <code>a</code> 和 <code>b</code> 的列进行了合并，行数不变，列数变为原来两个张量列数之和。在处理多模态数据时，比如一个模态的数据特征用张量 <code>a</code> 表示，另一个模态的数据特征用张量 <code>b</code> 表示，通过这种拼接操作可以将不同模态的特征合并在一起，方便后续的处理。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">张量 a：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">张量 b：</span><br><span class="line">tensor([[<span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">拼接后的张量 c：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure>

<p>在二维张量的语境下，维度 0 代表行方向。<code>torch.cat((a, b), dim=0)</code> 会将张量 <code>b</code> 按行的顺序拼接到张量 <code>a</code> 的下方，拼接后的张量列数不变，行数为原来两个张量行数之和。在实际应用中，若 <code>a</code> 和 <code>b</code> 分别表示两组样本数据，在维度 0 上拼接就相当于将这两组样本合并成一组更大的样本集。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">张量 a：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">张量 b：</span><br><span class="line">tensor([[<span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line">在维度 <span class="number">0</span> 上拼接后的张量 c：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">7</span>, <span class="number">8</span>]])</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong><code>torch.reshape()</code></strong>：改变张量的形状。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([1, 2, 3, 4])</span><br><span class="line">reshaped_x = torch.reshape(x, (2, 2))</span><br></pre></td></tr></table></figure>

<p>在神经网络中，不同层之间的数据形状可能需要进行调整，使用 <code>torch.reshape()</code> 可以方便地改变张量形状以满足层的输入要求。</p>
<p><code>torch.reshape(x, (2, 2))</code> 是将一维张量 <code>x</code> 重塑为二维张量 <code>reshaped_x</code>，形状为 <code>(2, 2)</code>。在神经网络中，不同层之间的数据形状可能不匹配，例如某一层的输出是一维向量，而后续层需要二维矩阵作为输入，这时就可以使用 <code>torch.reshape()</code> 来调整数据的形状，使其满足层的输入要求。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原始张量 x：</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">重塑后的张量 reshaped_x：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong><code>torch.transpose()</code></strong>：交换张量的两个维度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([[1, 2], [3, 4]])</span><br><span class="line">transposed_x = torch.transpose(x, 0, 1)</span><br></pre></td></tr></table></figure>

<p>在矩阵运算中，有时需要对矩阵进行转置操作。在图像处理中，可能需要调整图像张量的维度顺序。</p>
<p><code>torch.transpose(x, 0, 1)</code> 表示交换张量 <code>x</code> 的第 0 维和第 1 维。在这个二维矩阵的例子中，就是对矩阵进行了转置操作，原来的行变成了列，列变成了行。在矩阵运算中，矩阵转置是一个常见的操作，例如在计算矩阵乘法时可能需要对矩阵进行转置。在图像处理中，图像张量的维度顺序可能需要调整，比如将 <code>(高度, 宽度, 通道数)</code> 调整为 <code>(通道数, 高度, 宽度)</code> 以适应某些模型的输入要求，这时就可以使用 <code>torch.transpose()</code> 来实现。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">原始张量 x：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">转置后的张量 transposed_x：</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>torch.squeeze()</code>：移除张量中所有维度为 1 的轴（或指定轴）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([[[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]])  <span class="comment"># 形状 [1, 3, 1]</span></span><br><span class="line">y = torch.squeeze(x)                 <span class="comment"># 形状变为 [3]</span></span><br></pre></td></tr></table></figure>

<p>在张量操作中，某些操作（如池化、索引）可能产生冗余的维度为 1 的轴。例如：</p>
<ul>
<li>处理单通道图像时，通道维度可能为 1。</li>
<li>批量处理单个样本时，批量维度可能为 1。</li>
<li>某些神经网络层的输出可能保留不必要的单维度。</li>
</ul>
<p><code>torch.squeeze()</code> 默认移除所有大小为 1 的维度，也可指定 <code>dim</code> 参数移除特定轴（仅当该轴大小为 1 时生效）。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入张量 x：</span><br><span class="line">tensor([[[<span class="number">1</span>],</span><br><span class="line">         [<span class="number">2</span>],</span><br><span class="line">         [<span class="number">3</span>]]])</span><br><span class="line">输出张量 y：</span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">squeeze() 移除了所有大小为 <span class="number">1</span> 的维度（第 <span class="number">0</span> 维和第 <span class="number">2</span> 维），仅保留第 <span class="number">1</span> 维（大小为 <span class="number">3</span>）。</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h4><h5 id="前向传播（Forward-Propagation）"><a href="#前向传播（Forward-Propagation）" class="headerlink" title="前向传播（Forward Propagation）"></a>前向传播（Forward Propagation）</h5><ol>
<li>定义</li>
</ol>
<p>前向传播是深度学习模型处理输入数据以产生输出的过程。在这个过程中，输入数据从输入层开始，依次经过神经网络的各个隐藏层，每层都会对输入进行特定的数学变换（如加权求和后通过激活函数），最终到达输出层得到预测结果。可以将其看作是信息从输入向输出流动的过程，每一层根据前一层的输出计算本层的输出，逐步传递直至得到最终输出。</p>
<ol start="2">
<li>作用</li>
</ol>
<p>根据当前模型的参数（权重和偏置）对输入数据进行预测。通过一系列的线性和非线性变换，模型能够学习到输入数据中的特征模式，并将其映射到输出空间。例如，在图像分类任务中，前向传播可以将输入的图像转换为不同类别的概率分布，从而判断图像所属的类别。它为后续的反向传播提供了预测结果，是整个深度学习训练过程的基础步骤。</p>
<h5 id="反向传播（Backward-Propagation）"><a href="#反向传播（Backward-Propagation）" class="headerlink" title="反向传播（Backward Propagation）"></a>反向传播（Backward Propagation）</h5><ol>
<li>定义</li>
</ol>
<p>反向传播是深度学习中用于计算损失函数（Loss Function）关于模型参数（权重和偏置）的梯度的算法。它基于链式法则，从输出层开始，将损失函数的误差沿着计算图反向传播到输入层，依次计算每一层参数的梯度。简单来说，反向传播是在已知前向传播得到的预测结果和真实标签的情况下，计算如何调整模型参数可以减小损失的过程。</p>
<ol start="2">
<li>作用</li>
</ol>
<p>为模型参数的更新提供依据。在深度学习中，通常使用优化算法（如随机梯度下降，Stochastic Gradient Descent，SGD）来更新模型的参数，而这些优化算法需要知道损失函数关于参数的梯度。反向传播通过高效地计算这些梯度，使得模型能够根据预测误差自动调整参数，从而不断优化模型的性能。通过多次迭代前向传播和反向传播，模型可以逐渐学习到输入数据和输出标签之间的映射关系，提高预测的准确性。</p>
<h5 id="计算图与梯度追踪（可略过）"><a href="#计算图与梯度追踪（可略过）" class="headerlink" title="计算图与梯度追踪（可略过）"></a>计算图与梯度追踪（可略过）</h5><ol>
<li><code>requires_grad</code>设置张量是否需要进行梯度追踪</li>
</ol>
<p>在深度学习模型训练过程中，需要计算损失函数关于模型参数的梯度，以便使用优化算法（如随机梯度下降）更新参数。通过将模型参数张量的 <code>requires_grad</code> 设置为 <code>True</code>，可以利用自动求导机制自动计算梯度。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">2.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = x ** <span class="number">2</span></span><br><span class="line">y.backward()</span><br><span class="line"><span class="built_in">print</span>(x.grad)  <span class="comment"># 输出 4.0</span></span><br></pre></td></tr></table></figure>

<p><code>requires_grad</code> 是 PyTorch 张量的一个属性，当将其设置为 <code>True</code> 时，PyTorch 会开始追踪该张量的所有操作，构建计算图。计算图是一个有向无环图，它记录了从输入张量到输出张量的所有操作路径。</p>
<p>在上述示例中，我们创建了一个张量 <code>x</code> 并将 <code>requires_grad</code> 设置为 <code>True</code>，然后定义了一个函数 <code>y = x ** 2</code>。PyTorch 会自动记录这个操作，构建相应的计算图。</p>
<p>调用 <code>y.backward()</code> 方法时，PyTorch 会根据链式法则沿着计算图反向传播，计算出 <code>y</code> 关于 <code>x</code> 的梯度，并将梯度存储在 <code>x.grad</code> 属性中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x 的梯度: tensor([4.])</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>grad_fn</code> 属性与反向传播链</li>
</ol>
<p><strong><code>grad_fn</code></strong>：PyTorch 张量的属性，指向创建该张量的函数对象，用于记录操作历史以支持反向传播求梯度。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个需要梯度追踪的张量</span></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 定义操作 y = x^2</span></span><br><span class="line">y = x ** <span class="number">2</span></span><br><span class="line"><span class="comment"># 定义操作 z = y * 3</span></span><br><span class="line">z = y * <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印每个张量的 grad_fn</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y 的 grad_fn:&quot;</span>, y.grad_fn)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;z 的 grad_fn:&quot;</span>, z.grad_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行反向传播</span></span><br><span class="line">z.backward()</span><br><span class="line"><span class="comment"># 打印 x 的梯度</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x 的梯度:&quot;</span>, x.grad)</span><br></pre></td></tr></table></figure>

<p>在深度学习模型训练时，需要计算损失函数关于模型参数的梯度。由于模型中存在大量复杂的运算，通过 <code>grad_fn</code> 记录的操作历史，PyTorch 可以构建反向传播链，从而准确计算出梯度，为参数更新提供依据。</p>
<p>在上述代码中，首先创建了一个开启梯度追踪的张量 <code>x</code>。当执行 $y &#x3D; x^2$操作时，PyTorch 会创建一个表示平方操作的函数对象，<code>y.grad_fn</code> 就会指向这个函数对象，以此记录下 <code>y</code> 是由 <code>x</code> 经过平方操作得到的。接着执行 $z &#x3D; 3y$，同样地，<code>z.grad_fn</code> 会指向表示乘法操作的函数对象，记录 <code>z</code> 的计算来源。</p>
<p>当调用 <code>z.backward()</code> 时，PyTorch 会从 <code>z</code> 开始，依据 <code>z.grad_fn</code> 找到创建 <code>z</code> 的操作，然后通过这个操作回溯到 <code>y</code>，再根据 <code>y.grad_fn</code> 回溯到 <code>x</code>。在这个回溯过程中，按照链式法则逐步计算出 <code>z</code> 关于 <code>x</code> 的梯度，并将其存储在 <code>x.grad</code> 中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y 的 grad_fn: &lt;PowBackward0 object at 0x...&gt;</span><br><span class="line">z 的 grad_fn: &lt;MulBackward0 object at 0x...&gt;</span><br><span class="line">x 的梯度: tensor([12.])</span><br></pre></td></tr></table></figure>

<p><code>&lt;PowBackward0 object at 0x...&gt;</code> 是 PyTorch 中用于表示反向传播过程中特定操作的梯度计算函数对象的字符串表示形式。</p>
<p><strong>反向传播函数对象</strong>：在 PyTorch 的自动求导机制里，对张量进行各种运算（如加法、乘法、幂运算等）时，PyTorch 会构建一个计算图来记录这些操作的顺序和依赖关系。每个操作在计算图中都对应一个前向传播函数（用于计算输出结果）和一个反向传播函数（用于计算梯度）。</p>
<p><code>PowBackward0</code> 的意义：<code>PowBackward0</code> 表示的是幂运算的反向传播函数。执行 $y &#x3D; x^2$这样的幂运算时，<code>y</code> 的 <code>grad_fn</code> 属性就会指向一个 <code>PowBackward0</code> 对象，这个对象负责在反向传播过程中计算关于输入张量 <code>x</code> 的梯度。<strong><code>at 0x...</code></strong>：<code>at 0x...</code> 后面跟着的是该对象在内存中的地址。这个地址是系统为该对象分配的唯一标识符，用于在内存中定位该对象。</p>
<h5 id="梯度控制（可略过）"><a href="#梯度控制（可略过）" class="headerlink" title="梯度控制（可略过）"></a>梯度控制（可略过）</h5><p>1.<code>torch.no_grad()</code> 上下文管理器</p>
<p>用于临时禁止 PyTorch 的梯度计算功能，在其作用域内创建或操作的张量不会进行梯度追踪。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个需要梯度追踪的张量</span></span><br><span class="line">x = torch.tensor([<span class="number">2.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 torch.no_grad() 上下文管理器</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    y = x ** <span class="number">2</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;y 是否进行梯度追踪:&quot;</span>, y.requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在上下文管理器外进行操作</span></span><br><span class="line">z = x ** <span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;z 是否进行梯度追踪:&quot;</span>, z.requires_grad)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y 是否进行梯度追踪: False</span><br><span class="line">z 是否进行梯度追踪: True（z在上下文管理器外进行操作）</span><br></pre></td></tr></table></figure>

<p>2.<code>detach()</code> 分离计算图  </p>
<p><strong><code>detach()</code></strong>：用于将张量从当前计算图中分离，返回一个和原张量数据相同但不记录梯度信息、不参与反向传播的新张量。</p>
<ul>
<li>在模型评估阶段，只需得到预测结果，无需计算梯度，用 <code>detach()</code> 可节省内存和计算资源。</li>
<li>在多模型联合训练时，若某个模型输出用于另一模型但不影响自身梯度计算，可使用 <code>detach()</code> 分离。（核心还是节省内存和计算资源）</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建需梯度追踪的张量</span></span><br><span class="line">x = torch.tensor([<span class="number">3.0</span>], requires_grad=<span class="literal">True</span>)</span><br><span class="line">y = <span class="number">2</span> * x</span><br><span class="line"><span class="comment"># 分离计算图</span></span><br><span class="line">y_detached = y.detach()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原张量 y 是否追踪梯度:&quot;</span>, y.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分离后的张量 y_detached 是否追踪梯度:&quot;</span>, y_detached.requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    y_detached.backward()</span><br><span class="line"><span class="keyword">except</span> RuntimeError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;错误信息: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>上述代码里，<code>x</code> 开启梯度追踪，<code>y = 2 * x</code> 会记录在计算图中。调用 <code>y.detach()</code> 后得到 <code>y_detached</code>，它和 <code>y</code> 数据相同，但不追踪梯度。尝试对 <code>y_detached</code> 反向传播会报错，因为它已和计算图分离，无梯度信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原张量 y 是否追踪梯度: True</span><br><span class="line">分离后的张量 y_detached 是否追踪梯度: False</span><br><span class="line">错误信息: element 0 of tensors does not require grad and does not have a grad_fn</span><br></pre></td></tr></table></figure>

<p>3.<code>zero_grad()</code> (梯度清零) </p>
<p>在深度学习模型的训练过程中，通常会按批次（batch）输入数据进行训练。每次反向传播计算得到的梯度会累加到模型参数的 <code>.grad</code> 属性中。如果不进行梯度清零，那么下一次计算的梯度会与之前的梯度累加，导致梯度计算错误。因此，在每个批次训练开始前，需要调用 <code>zero_grad()</code> 方法将梯度清零，以确保每个批次的梯度计算是独立的。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个简单的线性模型</span></span><br><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟输入数据</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">target = torch.randn(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">output = model(input_tensor)</span><br><span class="line"><span class="comment"># 计算损失</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 反向传播计算梯度</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;反向传播后第一个参数的梯度:&quot;</span>, model.weight.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度清零</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;梯度清零后第一个参数的梯度:&quot;</span>, model.weight.grad)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">反向传播后第一个参数的梯度: tensor([[ 0.1234, -0.5678, ...]])</span><br><span class="line">梯度清零后第一个参数的梯度: tensor([[ 0., 0., ...]])</span><br></pre></td></tr></table></figure>

<h4 id="神经网络层"><a href="#神经网络层" class="headerlink" title="神经网络层"></a>神经网络层</h4><h5 id="核心基类-nn-Module"><a href="#核心基类-nn-Module" class="headerlink" title="核心基类 nn.Module"></a>核心基类 <code>nn.Module</code></h5><h6 id="什么是核心基类-nn-Module？"><a href="#什么是核心基类-nn-Module？" class="headerlink" title="什么是核心基类 nn.Module？"></a>什么是核心基类 <code>nn.Module</code>？</h6><p><strong><code>nn.Module</code></strong>：PyTorch 中所有神经网络模块的基类，用于构建自定义的神经网络模型，封装了模型的结构和参数，方便进行前向传播、参数管理和模型保存等操作。</p>
<p>在深度学习中，我们需要构建各种各样的神经网络模型，如卷积神经网络（CNN）、循环神经网络（RNN）等。<code>nn.Module</code> 提供了一个统一的框架，使得我们可以方便地定义和管理这些模型。无论是简单的全连接网络还是复杂的深度网络，都可以通过继承 <code>nn.Module</code> 来构建。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义一个简单的神经网络模型，继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 定义一个全连接层，输入维度为 10，输出维度为 1</span></span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 定义前向传播过程</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"><span class="comment"># 模拟输入数据</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output = model(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型结构：&quot;</span>, model)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入张量形状：&quot;</span>, input_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量形状：&quot;</span>, output.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong><code>__init__</code> 方法</strong>：在自定义的模型类中，<code>__init__</code> 方法用于初始化模型的各个层。通过调用 <code>super(SimpleNet, self).__init__()</code> 确保父类 <code>nn.Module</code> 的初始化被正确执行。然后定义了一个全连接层 <code>self.fc</code>。</li>
<li><strong><code>forward</code> 方法</strong>：<code>forward</code> 方法定义了模型的前向传播过程，即输入数据如何经过各个层得到输出。在这个例子中，输入数据 <code>x</code> 经过全连接层 <code>self.fc</code> 得到输出。</li>
<li>模型实例化和前向传播：创建 <code>SimpleNet</code> 的实例 <code>model</code> 后，将输入张量 <code>input_tensor</code> 传递给 <code>model</code> 就相当于调用了 <code>forward</code> 方法进行前向传播，得到输出 <code>output</code>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">模型结构： SimpleNet(</span><br><span class="line">  (fc): Linear(in_features=10, out_features=1, bias=True)</span><br><span class="line">)</span><br><span class="line">输入张量形状： torch.Size([1, 10])</span><br><span class="line">输出张量形状： torch.Size([1, 1])</span><br></pre></td></tr></table></figure>

<h6 id="自定义模型继承方法"><a href="#自定义模型继承方法" class="headerlink" title="自定义模型继承方法"></a>自定义模型继承方法</h6><ol>
<li>参数管理<code>parameters()</code>，<code>named_parameters()</code></li>
</ol>
<p><strong><code>parameters()</code></strong>：是 <code>nn.Module</code> 类的一个方法，它返回一个包含模型所有可学习参数的迭代器。通过遍历这个迭代器，能依次获取到模型中的各个参数张量，但不会提供参数的名称信息。</p>
<p><strong><code>named_parameters()</code></strong>：同样是 <code>nn.Module</code> 类的方法，它返回一个迭代器，该迭代器会生成模型可学习参数的名称和对应参数张量的元组。借助这个方法，我们不仅能获取参数张量，还能明确每个参数对应的名称，这在模型参数管理和调试时非常有用。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个简单的神经网络模型，继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="comment"># 定义一个全连接层，输入维度为 10，输出维度为 5</span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># 定义另一个全连接层，输入维度为 5，输出维度为 1</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 parameters() 方法获取模型参数的迭代器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;使用 parameters() 获取参数：&quot;</span>)</span><br><span class="line">params = model.parameters()</span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> params:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;参数形状: <span class="subst">&#123;param.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 named_parameters() 方法获取模型带名称的参数迭代器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n使用 named_parameters() 获取参数：&quot;</span>)</span><br><span class="line">named_params = model.named_parameters()</span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> named_params:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;参数名称: <span class="subst">&#123;name&#125;</span>, 参数形状: <span class="subst">&#123;param.shape&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong><code>parameters()</code></strong>：主要用于优化器初始化。在训练模型时，优化器（如 <code>torch.optim.SGD</code>、<code>torch.optim.Adam</code> 等）需要知道模型的可学习参数，以便对这些参数进行梯度更新。由于优化器只关心参数张量本身，不需要参数名称，所以使用 <code>parameters()</code> 即可。</p>
<p><strong><code>named_parameters()</code></strong>：在模型调试、参数分组优化或模型参数的选择性加载时非常有用。例如，你可能只想更新模型中某些特定层的参数，通过参数名称可以方便地筛选出这些参数；或者在加载预训练模型时，根据参数名称选择性地加载部分参数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">使用 parameters() 获取参数：</span><br><span class="line">参数形状: torch.Size([5, 10])</span><br><span class="line">参数形状: torch.Size([5])</span><br><span class="line">参数形状: torch.Size([1, 5])</span><br><span class="line">参数形状: torch.Size([1])</span><br><span class="line"></span><br><span class="line">使用 named_parameters() 获取参数：</span><br><span class="line">参数名称: fc1.weight, 参数形状: torch.Size([5, 10])</span><br><span class="line">参数名称: fc1.bias, 参数形状: torch.Size([5])</span><br><span class="line">参数名称: fc2.weight, 参数形状: torch.Size([1, 5])</span><br><span class="line">参数名称: fc2.bias, 参数形状: torch.Size([1])</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>train()</code> 与 <code>eval()</code> 模式切换</li>
</ol>
<p><code>train()</code> 和 <code>eval()</code> 是 <code>nn.Module</code> 类中的方法，用于切换模型的训练和评估模式。<code>train()</code> 方法将模型设置为训练模式，<code>eval()</code> 方法将模型设置为评估模式，不同模式下部分层（如 <code>Dropout</code>、<code>BatchNorm</code>）会有不同的行为。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个包含 Dropout 层的简单神经网络模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(p=<span class="number">0.5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型实例</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为训练模式</span></span><br><span class="line">model.train()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练模式下 Dropout 是否启用:&quot;</span>, model.dropout.training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为评估模式</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;评估模式下 Dropout 是否启用:&quot;</span>, model.dropout.training)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟输入数据</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    output_eval = model(input_tensor)</span><br><span class="line">model.train()</span><br><span class="line">output_train = model(input_tensor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;评估模式输出:&quot;</span>, output_eval)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练模式输出:&quot;</span>, output_train)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>训练模式（<code>train()</code>）</strong>：在模型训练阶段使用，此时模型中的 <code>Dropout</code> 层会按照设定的概率随机丢弃部分神经元，<code>BatchNorm</code> 层会根据当前批次的数据更新统计信息（如均值和方差），有助于提高模型的泛化能力。</li>
<li><strong>评估模式（<code>eval()</code>）</strong>：在模型评估、测试或者推理阶段使用。在评估模式下，<code>Dropout</code> 层不再丢弃神经元，<code>BatchNorm</code> 层使用训练阶段统计得到的均值和方差进行归一化操作，保证评估结果的稳定性和一致性。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">训练模式下 Dropout 是否启用: True</span><br><span class="line">评估模式下 Dropout 是否启用: False</span><br><span class="line">评估模式输出: tensor([[...]], grad_fn=&lt;AddmmBackward0&gt;)</span><br><span class="line">训练模式输出: tensor([[...]], grad_fn=&lt;AddmmBackward0&gt;)</span><br></pre></td></tr></table></figure>

<p>这里具体的输出数值会因随机生成的输入数据和模型初始化不同而有所变化，但可以看到在不同模式下 <code>Dropout</code> 层的行为不同，导致输出结果也可能不同。</p>
<h5 id="网络层-Layers"><a href="#网络层-Layers" class="headerlink" title="网络层 (Layers)"></a>网络层 (Layers)</h5><h6 id="基础层"><a href="#基础层" class="headerlink" title="基础层"></a>基础层</h6><ol>
<li><code>nn.Linear</code>全连接层</li>
</ol>
<p><strong><code>nn.Linear</code></strong>：PyTorch 中用于创建全连接层（也称为线性层）的类，它对输入数据进行线性变换，即执行矩阵乘法和加法操作，可用于构建各种神经网络模型。</p>
<p><strong>神经网络基础构建</strong>：全连接层是神经网络中最基本的组成部分之一，常用于多层感知机（MLP）的构建，可处理各种类型的数据，如图像、文本等特征向量。</p>
<p><strong>特征映射</strong>：可以将输入数据从一个特征空间映射到另一个特征空间，有助于模型学习数据中的复杂模式和特征表示。</p>
<hr>
<p>为什么是全连接层？</p>
<p>1.连接方式：在全连接层中，每一个输入神经元都与每一个输出神经元相连接，这种连接是 “全” 的，即完全连接。对于 </p>
<p><code>nn.Linear(in_features, out_features)</code> ，输入的 <code>in_features</code> 个神经元和输出的 <code>out_features</code> 个神经元之间存在着完整的连接关系。</p>
<p>2.数学运算：假设输入向量$X$维度为$n$（即 <code>in_features</code>），输出向量$Y$维度为$m$（即 <code>out_features</code>），全连接层通过权重矩阵$W$（形状为$m × n$）和偏置向量$b$（形状为$m$）进行线性变换$Y&#x3D;WX+b$。这里的权重矩阵$W$描述了输入神经元和输出神经元之间所有可能的连接强度，每一个输入元素都会影响到每一个输出元素的计算结果，这种全面的连接关系是 “全连接” 概念的核心体现。</p>
<p>3.网络结构对比：在神经网络中，除了全连接层，还有<strong>其他类型的层</strong>，比如卷积层、池化层等。卷积层中，神经元只与输入数据的局部区域相连接，而<strong>不是像全连接层那样与所有输入神经元连接</strong>；池化层则主要进行下采样操作，不存在像全连接层这样全面的神经元连接模式。因此，为了突出这种所有输入和输出神经元之间都有连接的特殊结构，将其称为全连接层，以便和其他类型的层进行区分。</p>
<hr>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个全连接层，输入维度为 10，输出维度为 5</span></span><br><span class="line">linear_layer = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟输入数据，假设有 1 个样本，每个样本有 10 个特征</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output = linear_layer(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全连接层的权重形状:&quot;</span>, linear_layer.weight.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;全连接层的偏置形状:&quot;</span>, linear_layer.bias.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入张量的形状:&quot;</span>, input_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量的形状:&quot;</span>, output.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>初始化参数</strong>：<code>nn.Linear(in_features, out_features)</code> 中，<code>in_features</code> 表示输入特征的数量，<code>out_features</code> 表示输出特征的数量。在上述代码中，<code>in_features = 10</code>，<code>out_features = 5</code>，意味着输入的每个样本有 10 个特征，经过全连接层后输出的每个样本有 5 个特征。</li>
<li><strong>线性变换</strong>：全连接层的计算过程可以表示为$Y&#x3D;XW^T+b$ ，其中$X$是输入向量，$W$是权重矩阵，形状为 <code>(out_features, in_features)</code>，$b$是偏置向量，形状为 <code>(out_features,)</code>，$Y$是输出向量。</li>
<li><strong>前向传播</strong>：将输入张量 <code>input_tensor</code> 传递给 <code>linear_layer</code> 时，会自动执行上述线性变换，得到输出张量 <code>output</code>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">全连接层的权重形状: torch.Size([5, 10])</span><br><span class="line">全连接层的偏置形状: torch.Size([5])</span><br><span class="line">输入张量的形状: torch.Size([1, 10])</span><br><span class="line">输出张量的形状: torch.Size([1, 5])</span><br></pre></td></tr></table></figure>

<ul>
<li><input disabled="" type="checkbox"> 权重形状的确定:</li>
</ul>
<p>为了使矩阵乘法$WX$能够得到维度为$m$的输出向量，权重矩阵$W$的形状必须是$m × n$。这是因为在矩阵乘法中，两个矩阵能够相乘的条件是前一个矩阵的列数等于后一个矩阵的行数，并且相乘结果矩阵的行数等于前一个矩阵的行数，列数等于后一个矩阵的列数。即如果$W$是$m × n$矩阵，$X$是$n × 1$向量，那么$WX$的结果就是一个$m × 1$向量，符合输出向量$Y$的维度要求。</p>
<p>在代码示例中，输入特征数量 <code>in_features = 10</code>，输出特征数量 <code>out_features = 5</code>，所以权重矩阵 的形状就是 <code>(5, 10)</code>，即 <code>torch.Size([5, 10])</code>。</p>
<ul>
<li><input disabled="" type="checkbox"> 偏置形状的确定</li>
</ul>
<p>偏置向量$b$的作用是在经过矩阵乘法得到的结果上进行偏移。由于输出向量$Y$的维度是$m$，为了能够对$WX$的每一个元素都加上一个偏移量，偏置向量$b$的维度也必须是$m$，即$b∈\R^m$。</p>
<p>在代码示例中，输出特征数量 <code>out_features = 5</code>，所以偏置向量 的形状就是 <code>(5,)</code>，即 <code>torch.Size([5])</code>。</p>
<ol start="2">
<li><code>nn.Bilinear</code>双线性层</li>
</ol>
<p><strong><code>nn.Bilinear</code></strong>：PyTorch 中的一个类，用于创建双线性层。双线性层对两个输入进行双线性变换，能捕捉两个输入之间的交互信息，是一种比普通线性层更复杂的变换形式。</p>
<p><strong>关系建模</strong>：在需要捕捉两个不同特征之间交互关系的任务中非常有用。例如，在推荐系统中，可以用双线性层来建模用户特征和物品特征之间的交互，以预测用户对物品的偏好；在自然语言处理中，可用于处理两个不同句子或不同语义表示之间的关系。</p>
<p><strong>融合多模态信息</strong>：当处理多模态数据（如图像和文本）时，双线性层可以帮助融合不同模态之间的信息，挖掘它们之间的潜在关联。</p>
<p><img src="/./%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250222212028325.png" alt="image-20250222212028325"></p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个双线性层</span></span><br><span class="line"><span class="comment"># 第一个输入维度为 10，第二个输入维度为 20，输出维度为 5</span></span><br><span class="line">bilinear_layer = nn.Bilinear(<span class="number">10</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟两个输入张量</span></span><br><span class="line"><span class="comment"># 第一个输入：假设有 1 个样本，每个样本有 10 个特征</span></span><br><span class="line">input1 = torch.randn(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 第二个输入：假设有 1 个样本，每个样本有 20 个特征</span></span><br><span class="line">input2 = torch.randn(<span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output = bilinear_layer(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;双线性层的权重形状:&quot;</span>, bilinear_layer.weight.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;双线性层的偏置形状:&quot;</span>, bilinear_layer.bias.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一个输入张量的形状:&quot;</span>, input1.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第二个输入张量的形状:&quot;</span>, input2.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量的形状:&quot;</span>, output.shape)</span><br></pre></td></tr></table></figure>

<p>权重张量的形状符合 <code>(out_features, in1_features, in2_features)</code>，偏置向量的长度等于输出特征的数量，两个输入张量经过双线性层后，输出张量的特征数量变为 <code>out_features</code> 设定的值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">双线性层的权重形状: torch.Size([5, 10, 20])</span><br><span class="line">双线性层的偏置形状: torch.Size([5])</span><br><span class="line">第一个输入张量的形状: torch.Size([1, 10])</span><br><span class="line">第二个输入张量的形状: torch.Size([1, 20])</span><br><span class="line">输出张量的形状: torch.Size([1, 5])</span><br></pre></td></tr></table></figure>

<h6 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h6><hr>
<p>1.什么是卷积层？</p>
<p>卷积层本质上是通过可学习的卷积核（滤波器）在输入数据上进行滑动并执行卷积操作，以提取输入数据中的局部特征模式，同时利用参数共享减少模型参数数量。</p>
<p>卷积操作指的是卷积核（一个小的矩阵）在输入数据（如图像矩阵）上按一定步长滑动，每滑动到一个位置，就将卷积核与该位置对应的输入局部区域元素对应相乘后求和，得到输出特征图的一个值，不断滑动直至覆盖整个输入数据，最终生成完整的输出特征图。</p>
<p>假设输入是一个 4×4 的单通道图像矩阵，使用一个 2×2 的卷积核进行卷积操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">输入图像矩阵：</span><br><span class="line">[[1 2 3 4]</span><br><span class="line"> [5 6 7 8]</span><br><span class="line"> [9 10 11 12]</span><br><span class="line"> [13 14 15 16]]</span><br><span class="line"></span><br><span class="line">卷积核：</span><br><span class="line">[[1 2]</span><br><span class="line"> [3 4]]</span><br><span class="line"> </span><br><span class="line">第一步：卷积核位于输入图像的左上角，覆盖的局部区域是：</span><br><span class="line">[[1 2]</span><br><span class="line"> [5 6]]</span><br><span class="line">将卷积核与该局部区域对应元素相乘再求和：</span><br><span class="line">(1x1+2x2)+(3x5+4x6)=44</span><br><span class="line">这个 44 就是输出特征图左上角的值。</span><br><span class="line"></span><br><span class="line">第二步：卷积核向右滑动一个步长（假设步长为 1），覆盖的局部区域变为：</span><br><span class="line">[[2 3]</span><br><span class="line"> [6 7]]</span><br><span class="line">同样进行对应元素相乘再求和的操作：</span><br><span class="line">(1x2+2x3)+(3x6+4x7)=54</span><br><span class="line">这是输出特征图中左上角右侧位置的值。</span><br><span class="line"></span><br><span class="line">后续步骤：卷积核继续向右、向下滑动，每次都重复上述相乘求和的操作，直到遍历完整个输入图像矩阵，最终得到一个 3×3 的输出特征图（因为 4×4 的输入矩阵使用 2×2 卷积核，步长为 1 时会得到 3×3 的输出）。</span><br></pre></td></tr></table></figure>

<p>2.卷积层有什么好处？</p>
<p><strong>减少参数数量</strong></p>
<p>卷积层使用参数共享机制，即一个卷积核在整个输入数据上滑动使用，相比于全连接层每个输出神经元都与所有输入相连，大大减少了需要学习的参数数量，降低计算量和存储需求，也减少了过拟合风险。</p>
<p><strong>提取局部特征</strong></p>
<p>卷积核在输入数据的局部区域进行操作，能够有效捕捉数据中的局部特征，如在图像中可检测边缘、纹理等。这些局部特征在不同位置可能具有相似性，卷积层可以很好地学习和利用这种特性。</p>
<p><strong>保留空间结构</strong></p>
<p>卷积操作基于局部连接，能保留输入数据的空间结构信息，这对于处理具有空间结构的数据（如图像、音频）非常重要，有助于模型理解数据中元素之间的相对位置关系。</p>
<p><strong>可构建深层网络</strong></p>
<p>多个卷积层可以堆叠形成深层卷积神经网络，随着网络深度增加，能学习到从简单到复杂、从底层到高层的多层次特征，提升模型在各种任务（如图像分类、目标检测）中的性能。</p>
<hr>
<ol>
<li><code>nn.Conv1d</code> 1D卷积：处理时序数据（如音频、文本）</li>
</ol>
<p><code>nn.Conv1d</code> 是 PyTorch 中用于进行一维卷积操作的模块，主要用于处理时序数据，像音频信号、文本序列等。一维卷积在这些数据上沿着一个维度（通常是时间维度）进行卷积操作，能有效提取数据中的局部特征模式。</p>
<p><strong>音频处理</strong>：可以用于音频特征提取、语音识别等任务，通过一维卷积提取音频信号中的时域特征。</p>
<p><strong>文本处理</strong>：在自然语言处理中，将文本序列看作一维数据，一维卷积可以捕捉文本中的局部语义信息，常用于文本分类、情感分析等任务。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入数据</span></span><br><span class="line"><span class="comment"># 输入数据形状：(批量大小, 输入通道数, 序列长度)</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">16</span>, <span class="number">3</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一维卷积层</span></span><br><span class="line"><span class="comment"># in_channels: 输入通道数</span></span><br><span class="line"><span class="comment"># out_channels: 输出通道数</span></span><br><span class="line"><span class="comment"># kernel_size: 卷积核大小</span></span><br><span class="line">conv1d_layer = nn.Conv1d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行卷积操作</span></span><br><span class="line">output = conv1d_layer(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入张量形状:&quot;</span>, input_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量形状:&quot;</span>, output.shape)</span><br></pre></td></tr></table></figure>

<p><strong>输入数据</strong></p>
<p>通常是三维张量，形状为 <code>(batch_size, in_channels, sequence_length)</code>。其中 <code>batch_size</code> 表示一次处理的样本数量；<code>in_channels</code> 是输入数据的通道数，例如在音频处理中，单声道音频 <code>in_channels</code> 为 1，立体声音频 <code>in_channels</code> 为 2；<code>sequence_length</code> 是序列的长度，对于音频数据就是音频信号的采样点数，对于文本数据就是文本序列的长度。</p>
<p><strong>卷积层参数</strong></p>
<p><code>in_channels</code>：输入数据的通道数，必须与输入张量的第二维大小一致。</p>
<p><code>out_channels</code>：输出数据的通道数，即卷积层使用的卷积核数量。每个卷积核会提取一种特定的特征，因此不同的卷积核会输出不同的特征图。</p>
<p><code>kernel_size</code>：卷积核的大小，表示在序列维度上卷积核覆盖的元素个数。例如 <code>kernel_size=3</code> 表示卷积核在序列上每次覆盖 3 个元素。</p>
<p><strong>卷积操作过程</strong></p>
<p>卷积核在输入数据的序列维度上滑动，每次覆盖 <code>kernel_size</code> 个元素，并在每个通道上进行卷积操作，然后将各通道的结果相加（如果有多个输入通道），最后加上偏置项得到输出的一个值。卷积核不断滑动，最终得到输出特征图。</p>
<p><strong>输出数据</strong></p>
<p>输出数据同样是三维张量，形状为 <code>(batch_size, out_channels, new_sequence_length)</code>。其中 <code>batch_size</code> 与输入相同；<code>out_channels</code> 是卷积层定义的输出通道数；<code>new_sequence_length</code> 由输入序列长度、卷积核大小、步长（<code>stride</code>，默认为 1）和填充（<code>padding</code>，默认为 0）等因素决定，计算公式为：</p>
<p><img src="/./%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/image-20250222215408498.png" alt="image-20250222215408498"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入张量形状: torch.Size([16, 3, 100])</span><br><span class="line">输出张量形状: torch.Size([16, 6, 98])</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>nn.Conv2d</code> 2D卷积：处理图像数据</li>
</ol>
<p><code>nn.Conv2d</code>：PyTorch 中用于实现二维卷积操作的类，主要处理图像数据。通过可学习的卷积核在输入图像上滑动并进行卷积运算，提取图像局部特征，利用参数共享减少模型参数。</p>
<p><strong>图像分类</strong>：用于提取图像特征，结合后续层将图像映射到不同类别，如区分猫狗图像。</p>
<p><strong>目标检测</strong>：提取物体特征，配合检测算法确定图像中物体的位置和类别，像自动驾驶中检测车辆、行人。</p>
<p><strong>语义分割</strong>：对图像每个像素分类，将图像分割成不同语义区域，例如医学图像中分割肿瘤和正常组织。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备输入数据，仅保留第一张图片</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">in_channels = <span class="number">3</span></span><br><span class="line">height = <span class="number">4</span></span><br><span class="line">width = <span class="number">4</span></span><br><span class="line"><span class="comment"># 手动设定输入张量，方便后续手动计算验证</span></span><br><span class="line">input_tensor = torch.tensor([</span><br><span class="line">    [</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">         [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>],</span><br><span class="line">         [<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>],</span><br><span class="line">         [<span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>]],</span><br><span class="line">        [[<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">         [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>],</span><br><span class="line">         [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>],</span><br><span class="line">         [<span class="number">14</span>, <span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>]],</span><br><span class="line">        [[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">         [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>],</span><br><span class="line">         [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">         [<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>]]</span><br><span class="line">    ]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义卷积层</span></span><br><span class="line">out_channels = <span class="number">2</span></span><br><span class="line">kernel_size = <span class="number">2</span></span><br><span class="line">stride = <span class="number">1</span></span><br><span class="line">padding = <span class="number">0</span></span><br><span class="line">conv2d_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,</span><br><span class="line">                         kernel_size=kernel_size, stride=stride, padding=padding)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动设定卷积核权重，方便后续手动计算验证</span></span><br><span class="line"><span class="comment"># 这里假设的卷积核和前面理论部分一致</span></span><br><span class="line">conv2d_layer.weight.data = torch.tensor([</span><br><span class="line">    [</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">1</span>]],</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">0</span>]],</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">    ],</span><br><span class="line">    [</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">         [<span class="number">1</span>, <span class="number">1</span>]],</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">0</span>]],</span><br><span class="line">        [[<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">         [<span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line">    ]</span><br><span class="line">], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动设定偏置为 0，简化计算</span></span><br><span class="line">conv2d_layer.bias.data = torch.zeros(out_channels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行卷积操作</span></span><br><span class="line">output = conv2d_layer(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入张量形状:&quot;</span>, input_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;卷积核形状:&quot;</span>, conv2d_layer.weight.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量形状:&quot;</span>, output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;第一张图片的输出:&quot;</span>, output[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动计算第一张图片经过第一个卷积核的左上角输出值</span></span><br><span class="line">first_kernel_channel1 = torch.tensor([[<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>]], dtype=torch.float32)</span><br><span class="line">first_kernel_channel2 = torch.tensor([[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>]], dtype=torch.float32)</span><br><span class="line">first_kernel_channel3 = torch.tensor([[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">1</span>]], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个通道的局部卷积</span></span><br><span class="line">local_conv_channel1 = (input_tensor[<span class="number">0</span>, <span class="number">0</span>, :<span class="number">2</span>, :<span class="number">2</span>] * first_kernel_channel1).<span class="built_in">sum</span>()</span><br><span class="line"><span class="comment"># 第二个通道的局部卷积</span></span><br><span class="line">local_conv_channel2 = (input_tensor[<span class="number">0</span>, <span class="number">1</span>, :<span class="number">2</span>, :<span class="number">2</span>] * first_kernel_channel2).<span class="built_in">sum</span>()</span><br><span class="line"><span class="comment"># 第三个通道的局部卷积</span></span><br><span class="line">local_conv_channel3 = (input_tensor[<span class="number">0</span>, <span class="number">2</span>, :<span class="number">2</span>, :<span class="number">2</span>] * first_kernel_channel3).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多通道结果相加</span></span><br><span class="line">manual_output = local_conv_channel1 + local_conv_channel2 + local_conv_channel3</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;手动计算第一张图片经过第一个卷积核左上角输出值:&quot;</span>, manual_output)</span><br></pre></td></tr></table></figure>

<p>上述代码模拟了处理彩色图像的过程。输入数据是一个四维张量，形状为 <code>(batch_size, in_channels, height, width)</code>。例如，<code>batch_size = 1</code> 表示一次处理 1 张图像；<code>in_channels = 3</code> 对应 RGB 三个通道；<code>height = 4</code> 和 <code>width = 4</code> 是图像的高度和宽度。输入数据可以表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">输入数据形状: (2, 3, 4, 4)</span><br><span class="line">第 1 张图像通道 1:</span><br><span class="line">[[1, 2, 3, 4],</span><br><span class="line"> [5, 6, 7, 8],</span><br><span class="line"> [9, 10, 11, 12],</span><br><span class="line"> [13, 14, 15, 16]]</span><br><span class="line"></span><br><span class="line">第 1 张图像通道 2:</span><br><span class="line">[[2, 3, 4, 5],</span><br><span class="line"> [6, 7, 8, 9],</span><br><span class="line"> [10, 11, 12, 13],</span><br><span class="line"> [14, 15, 16, 17]]</span><br><span class="line"></span><br><span class="line">第 1 张图像通道 3:</span><br><span class="line">[[3, 4, 5, 6],</span><br><span class="line"> [7, 8, 9, 10],</span><br><span class="line"> [11, 12, 13, 14],</span><br><span class="line"> [15, 16, 17, 18]]</span><br><span class="line"></span><br><span class="line">...（其他图片类似）</span><br></pre></td></tr></table></figure>

<p>定义一个二维卷积层，设置参数如下：</p>
<ul>
<li><code>in_channels = 3</code>，与输入图像的通道数一致。</li>
<li><code>out_channels = 2</code>，表示使用 2 个卷积核。</li>
<li><code>kernel_size = 2</code>，卷积核是 2x2 的正方形。</li>
<li><code>stride = 1</code>，卷积核每次滑动 1 个单位。</li>
<li><code>padding = 0</code>，不进行填充。</li>
</ul>
<p>每个卷积核也是一个四维张量，形状为 <code>(out_channels, in_channels, kernel_height, kernel_width)</code>，这里是 <code>(2, 3, 2, 2)</code>。假设两个卷积核分别为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">卷积核 1:</span><br><span class="line">通道 1:</span><br><span class="line">[[1, 0],</span><br><span class="line"> [0, 1]]</span><br><span class="line"></span><br><span class="line">通道 2:</span><br><span class="line">[[0, 1],</span><br><span class="line"> [1, 0]]</span><br><span class="line"></span><br><span class="line">通道 3:</span><br><span class="line">[[1, 1],</span><br><span class="line"> [1, 1]]</span><br><span class="line"></span><br><span class="line">卷积核 2:</span><br><span class="line">通道 1:</span><br><span class="line">[[1, 1],</span><br><span class="line"> [1, 1]]</span><br><span class="line"></span><br><span class="line">通道 2:</span><br><span class="line">[[0, 0],</span><br><span class="line"> [0, 0]]</span><br><span class="line"></span><br><span class="line">通道 3:</span><br><span class="line">[[1, 0],</span><br><span class="line"> [0, 1]]</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">卷积操作</span><br><span class="line">以第 1 张图像为例，对于卷积核 1：</span><br><span class="line">通道 1 的卷积：卷积核在通道 1 的输入图像上滑动，计算局部区域与卷积核对应元素相乘再求和。例如，在左上角区域：</span><br><span class="line">通道 2 和通道 3 同样操作：得到各自的局部卷积结果。</span><br><span class="line">多通道结果相加：将三个通道的局部卷积结果相加，得到该位置的最终输出值。</span><br><span class="line">滑动卷积核：卷积核在图像上按步长 1 滑动，重复上述操作，得到卷积核 1 对第 1 张图像的输出特征图。</span><br><span class="line">对于卷积核 2 也进行同样的操作，最终得到两个输出特征图，这两个特征图组成了第 1 张图像经过卷积层后的输出。对于第 2 张图像，也重复上述卷积操作。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">输入张量形状: torch.Size([1, 3, 4, 4])</span><br><span class="line">卷积核形状: torch.Size([2, 3, 2, 2])</span><br><span class="line">输出张量形状: torch.Size([1, 2, 3, 3])</span><br><span class="line">第一张图片的输出:</span><br><span class="line">tensor([[[ 41.,  48.,  55.],</span><br><span class="line">         [ 65.,  72.,  79.],</span><br><span class="line">         [ 89.,  96., 103.]],</span><br><span class="line"></span><br><span class="line">        [[ 26.,  30.,  34.],</span><br><span class="line">         [ 46.,  50.,  54.],</span><br><span class="line">         [ 66.,  70.,  74.]]], grad_fn=&lt;SelectBackward0&gt;)</span><br><span class="line">手动计算第一张图片经过第一个卷积核左上角输出值: tensor(41.)</span><br></pre></td></tr></table></figure>

<hr>
<p>卷积核如何确定？</p>
<p>卷积核的确定需要综合考虑任务需求、数据特点、模型架构和计算资源等因素，并通过实验和调优不断优化，以达到最佳的性能。</p>
<hr>
<ol start="3">
<li><code>nn.Conv3d</code> 3D卷积：处理视频&#x2F;体数据</li>
</ol>
<p><code>nn.Conv3d</code> 是 PyTorch 中用于实现三维卷积操作的类，主要用于处理视频数据（包含时间维度和空间维度）或体数据（如医学影像中的三维体数据）。它通过可学习的三维卷积核在输入数据上进行滑动并执行卷积运算，提取数据中的三维特征，利用参数共享机制减少模型参数数量，降低计算复杂度。</p>
<p><strong>视频分类</strong>：在视频分类任务中，<code>nn.Conv3d</code> 用于提取视频的时空特征，通过多个卷积层和池化层的组合，将视频特征映射到不同的类别。例如，在识别视频中的动作类型（如跑步、跳舞、打球等）时，三维卷积可以捕捉视频中随时间变化的动作特征。</p>
<p><strong>医学影像分析</strong>：在医学影像分析中，如对 CT 或 MRI 扫描得到的三维体数据进行分析，<code>nn.Conv3d</code> 可以用于肿瘤检测、器官分割等任务。它能够提取体数据中的三维结构信息，帮助医生进行疾病诊断。</p>
<p><strong>自动驾驶场景</strong>：在自动驾驶中处理点云数据（可以看作三维空间中的数据）时，<code>nn.Conv3d</code> 可用于识别道路上的障碍物、车辆、行人等目标，通过分析点云数据的三维特征来辅助决策。</p>
<p><strong>卷积核与卷积操作</strong></p>
<p>三维卷积核是一个三维的矩阵，其元素是可学习的权重参数。在进行卷积操作时，三维卷积核会在输入的三维数据（如视频的多个帧组成的序列或者三维体数据）上按一定的步长进行滑动，每次覆盖一个与卷积核大小相同的三维局部区域。对于这个局部区域，将卷积核与该区域的元素对应相乘后求和，得到一个输出值，这个值就构成了输出特征体的一个元素。随着卷积核不断滑动，遍历整个输入三维数据，最终生成完整的输出特征体。</p>
<hr>
<p><code>nn.Conv1d/2d/3d</code>的共同原理与特征</p>
<p><strong>共同原理</strong></p>
<p>1.卷积操作核心</p>
<p>核心都是卷积运算。卷积核（也称为滤波器）是一组可学习的权重参数，在输入数据上按照一定规则滑动，每次覆盖一个局部区域，将卷积核与该局部区域的元素对应相乘后求和，得到一个输出值。这个过程不断重复，直到卷积核遍历完整个输入数据，从而生成输出特征。</p>
<p>以 <code>nn.Conv1d</code> 为例，输入是一维序列，卷积核也是一维的，在序列上滑动进行卷积；<code>nn.Conv2d</code> 输入是二维图像，卷积核是二维矩阵，在图像上滑动；<code>nn.Conv3d</code> 输入是三维数据（如视频或体数据），卷积核是三维的，在三维空间中滑动。</p>
<p>2.线性变换</p>
<p>卷积操作本质上是一种线性变换。对于输入数据的每个局部区域，卷积运算将其与卷积核进行加权求和，这相当于对输入数据进行了线性组合。这种线性变换使得模型能够学习到输入数据中的特征模式。</p>
<p>3.参数共享</p>
<p>在卷积过程中，卷积核的权重在整个输入数据上是共享的。也就是说，同一个卷积核在不同的位置进行卷积操作时，使用的是相同的权重参数。这大大减少了模型需要学习的参数数量，降低了计算复杂度，同时也提高了模型的泛化能力，使得模型能够在不同位置检测到相同的特征。</p>
<p>4.多通道处理</p>
<p>当输入数据具有多个通道时，每个卷积核也具有对应数量的通道。卷积操作会在每个通道上分别进行卷积，然后将各通道的结果相加，得到最终的输出值。例如，对于 RGB 图像（3 个通道），每个二维卷积核也有 3 个通道，分别对 R、G、B 通道进行卷积后求和。<code>nn.Conv1d</code>、<code>nn.Conv2d</code> 和 <code>nn.Conv3d</code> 都支持多通道输入和输出，通过使用多个卷积核可以得到多个通道的输出特征。</p>
<p><strong>共同特征</strong></p>
<p>1.可学习性</p>
<p>卷积核的权重参数是可学习的，在模型训练过程中，通过反向传播算法和优化器（如随机梯度下降、Adam 等）不断调整卷积核的权重，使得模型能够自动学习到输入数据中的有效特征，以适应不同的任务需求，如分类、检测、分割等。</p>
<p>2.局部感知</p>
<p>都具有局部感知的特性，即卷积核只关注输入数据的局部区域，而不是全局信息。这种局部感知能力使得模型能够捕捉到数据中的局部特征，如边缘、纹理、模式等。通过堆叠多个卷积层，模型可以逐渐学习到更高级、更抽象的特征。</p>
<p>3.平移不变性</p>
<p>由于参数共享的特性，卷积操作具有平移不变性。这意味着如果输入数据中的某个特征在不同位置出现，卷积核都能够检测到该特征，而不依赖于其具体位置。这种平移不变性使得模型在处理具有平移特性的数据时更加有效，例如图像中的物体在不同位置出现，模型都能够正确识别。</p>
<p>4.输出特征的维度调整</p>
<p>通过调整卷积核的大小、步长和填充等参数，可以控制输出特征的维度。步长越大，输出特征的维度越小；填充可以在输入数据的边缘添加额外的元素，从而保持输出特征的维度与输入数据相同或满足特定的要求。这种灵活性使得模型能够根据具体任务和数据特点进行合理的设计。</p>
<hr>
<ol start="4">
<li><code>nn.ConvTranspose1d/2d/3d</code> 转置卷积：反卷积（上采样）</li>
</ol>
<p><code>nn.ConvTranspose1d</code>、<code>nn.ConvTranspose2d</code> 和 <code>nn.ConvTranspose3d</code> 分别是 PyTorch 中用于一维、二维和三维转置卷积（也常被称为反卷积，但实际上并非严格意义的卷积逆运算，主要用于上采样）的类。转置卷积通过在输入数据上进行特殊的卷积操作，使得输出的尺寸比输入尺寸更大，实现数据的上采样，在图像生成、语义分割等任务中经常使用。</p>
<p>转置卷积本质上是标准卷积的一种 “逆向” 操作，但不是严格意义上的逆运算。在标准卷积中，卷积核在输入数据上滑动，将局部区域映射到一个输出值，导致输出尺寸通常小于输入尺寸。而转置卷积则是将输入的每个元素扩展到一个更大的区域，然后与卷积核进行卷积操作，从而实现输出尺寸大于输入尺寸的效果。</p>
<p>具体来说，转置卷积通过在输入数据周围插入零值（称为 “零填充”），并调整卷积核的滑动方式，使得卷积操作能够产生更大的输出。在一维、二维和三维的情况下，分别使用 <code>nn.ConvTranspose1d</code>、<code>nn.ConvTranspose2d</code> 和 <code>nn.ConvTranspose3d</code> 来实现相应维度的转置卷积。</p>
<blockquote>
<p>上采样：</p>
<p>指的是将低分辨率的数据转换为高分辨率数据的过程。在深度学习中，输入数据（如图像、特征图等）经过一系列下采样操作（如卷积、池化）后尺寸会变小，为了恢复到原始尺寸或达到特定任务所需的尺寸，就需要进行上采样操作。</p>
<ul>
<li><strong>恢复尺寸</strong>：在一些任务中，如语义分割，模型需要对输入图像的每个像素进行分类，经过下采样后的特征图尺寸变小，需要通过上采样恢复到与输入图像相同的尺寸，以便为每个像素分配类别标签。</li>
<li><strong>增加细节</strong>：上采样可以在一定程度上增加数据的细节信息，使模型能够学习到更丰富的特征，提升模型性能。</li>
</ul>
</blockquote>
<p><strong>图像生成</strong>：在生成对抗网络（GAN）和变分自编码器（VAE）等图像生成模型中，转置卷积用于将低维的特征向量逐步上采样为高分辨率的图像。例如，在生成手写数字图像时，模型从一个随机的低维向量开始，通过一系列的转置卷积层逐渐生成 28x28 像素的手写数字图像。</p>
<p><strong>语义分割</strong>：在语义分割任务中，模型需要将卷积层提取的低分辨率特征图恢复到与输入图像相同的尺寸，以便为每个像素分配一个类别标签。转置卷积可以有效地实现特征图的上采样，帮助模型生成与输入图像大小一致的分割结果。</p>
<p><strong>超分辨率重建</strong>：超分辨率重建任务旨在将低分辨率的图像恢复为高分辨率的图像。转置卷积可以用于逐步增加图像的分辨率，提高图像的清晰度和细节。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟低分辨率图像特征图，形状为 (批量大小, 输入通道数, 高度, 宽度)</span></span><br><span class="line">input_image = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二维转置卷积层，用于上采样图像</span></span><br><span class="line">conv_transpose2d = nn.ConvTranspose2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">3</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行转置卷积操作</span></span><br><span class="line">output_image = conv_transpose2d(input_image)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入图像特征图形状:&quot;</span>, input_image.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出图像特征图形状:&quot;</span>, output_image.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入图像特征图形状: torch.Size([1, 3, 8, 8])</span><br><span class="line">输出图像特征图形状: torch.Size([1, 3, 16, 16])</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><code>nn.Conv1d/2d/3d</code> （设置 <code>dilation</code>）空洞卷积：扩大感受野</li>
</ol>
<p><code>nn.Conv1d</code>、<code>nn.Conv2d</code> 和 <code>nn.Conv3d</code> 在设置 <code>dilation</code> 参数后可实现空洞卷积（也叫扩张卷积）。空洞卷积是对标准卷积的扩展，通过在卷积核元素之间插入空洞，在不增加参数数量的情况下扩大卷积核的感受野，使模型能够捕捉更大范围的上下文信息，常用于语义分割、目标检测等任务。</p>
<p>在标准卷积中，卷积核的元素是连续排列的，在输入数据上进行滑动卷积操作。而空洞卷积通过设置 <code>dilation</code> 参数，在卷积核元素之间插入空洞。例如，当 <code>dilation = 2</code> 时，卷积核元素之间会间隔一个位置，相当于在标准卷积核的基础上每隔一个元素设置为零，然后再进行卷积操作。这样，卷积核在输入数据上滑动时，能够覆盖更大的区域，从而扩大了感受野。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入张量</span></span><br><span class="line"><span class="comment"># 形状：(批量大小, 输入通道数, 高度, 宽度)</span></span><br><span class="line">input_tensor = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">16</span>, <span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义二维空洞卷积层</span></span><br><span class="line"><span class="comment"># 设置 dilation = 2 来实现空洞卷积</span></span><br><span class="line">conv2d_dilated = nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, dilation=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行空洞卷积操作</span></span><br><span class="line">output = conv2d_dilated(input_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入张量形状:&quot;</span>, input_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量形状:&quot;</span>, output.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入张量形状: torch.Size([1, 3, 16, 16])</span><br><span class="line">输出张量形状: torch.Size([1, 6, 16, 16])</span><br></pre></td></tr></table></figure>

<h6 id="循环神经网络层"><a href="#循环神经网络层" class="headerlink" title="循环神经网络层"></a>循环神经网络层</h6><p>循环神经网络层（Recurrent Neural Network layer，RNN layer）是一种专门用于处理序列数据的神经网络层结构。在很多实际应用场景中，数据具有序列特性，例如文本（由单词按顺序组成）、语音（音频信号随时间变化）、时间序列数据（如股票价格随时间的波动）等。与传统的前馈神经网络不同，循环神经网络层引入了循环结构，使得网络能够在处理序列数据时保留之前时间步的信息，从而更好地捕捉序列中的上下文关系和时间依赖。</p>
<p>RNN、LSTM 和 GRU 都属于循环神经网络层的范畴，它们在处理序列数据时各有特点。简单 RNN 结构简单但存在梯度问题；LSTM 通过门控机制解决了梯度问题但计算复杂；GRU 则在性能和计算效率之间取得了较好的平衡。根据不同的应用场景和数据特点，可以选择合适的循环神经网络层来构建模型。</p>
<p>1.<code>nn.RNN</code> RNN：基础循环网络</p>
<p><code>nn.RNN</code> 是 PyTorch 中用于构建基础循环神经网络（Recurrent Neural Network，RNN）的模块。RNN 是一种专门处理序列数据的神经网络，它通过在网络中引入循环结构，使得网络能够保存和利用之前时间步的信息，从而对序列中的时间依赖关系进行建模。不过，RNN 存在梯度消失或梯度爆炸问题，在处理长序列时表现不佳。</p>
<p>在每个时间步 ，RNN 接收当前输入$x_t$和上一个时间步的隐藏状态$h_{t-1}$，通过以下公式计算当前时间步的隐藏状态$h_t$：</p>
<p>$h_t&#x3D;tanh(W_{ih}x_t+W_{hh}h_{t-1}+b_h)$</p>
<p>其中$W_{ih}$是输入到隐藏状态的权重矩阵，$W_{hh}$是隐藏状态到隐藏状态的权重矩阵，$b_h$是偏置，$tanh$是激活函数，用于引入非线性。</p>
<p><strong>自然语言处理</strong>：如文本分类任务，将一段文本看作一个词序列，RNN 可以对文本中的语义信息进行建模，根据之前的词来预测当前词的类别概率；还可用于语言生成，例如生成诗歌、故事等，通过不断根据之前生成的词来预测下一个词。</p>
<p><strong>时间序列预测</strong>：像股票价格预测、天气预报等，把时间序列数据（如每天的股票价格、每小时的气温）作为输入，RNN 可以学习到序列中的趋势和模式，从而预测未来的值。</p>
<p><strong>语音识别</strong>：语音信号是随时间变化的序列，RNN 可以处理语音特征序列，根据之前的语音帧信息来识别当前帧对应的语音内容。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入参数</span></span><br><span class="line">input_size = <span class="number">10</span>  <span class="comment"># 输入特征维度</span></span><br><span class="line">hidden_size = <span class="number">20</span>  <span class="comment"># 隐藏状态维度</span></span><br><span class="line">num_layers = <span class="number">1</span>  <span class="comment"># RNN 层数</span></span><br><span class="line">batch_size = <span class="number">32</span>  <span class="comment"># 批量大小</span></span><br><span class="line">seq_len = <span class="number">5</span>  <span class="comment"># 序列长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 RNN 层</span></span><br><span class="line">rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成随机输入数据</span></span><br><span class="line">input_data = torch.randn(batch_size, seq_len, input_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化隐藏状态</span></span><br><span class="line">h_0 = torch.randn(num_layers, batch_size, hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output, h_n = rnn(input_data, h_0)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入数据形状:&quot;</span>, input_data.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出形状:&quot;</span>, output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终隐藏状态形状:&quot;</span>, h_n.shape)</span><br></pre></td></tr></table></figure>

<p>输入数据 <code>input_data</code> 是一个三维张量，当 <code>batch_first = True</code> 时，形状为 <code>(batch_size, seq_len, input_size)</code>，表示批量大小为 32，序列长度为 5，每个时间步的输入特征维度为 10。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">input_data = torch.randn(batch_size, seq_len, input_size)</span><br></pre></td></tr></table></figure>

<p>使用 <code>nn.RNN</code> 创建 RNN 层，设置输入特征维度、隐藏状态维度和层数等参数。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>初始化隐藏状态 <code>h_0</code>，形状为 <code>(num_layers, batch_size, hidden_size)</code>。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">h_0 = torch.randn(num_layers, batch_size, hidden_size)</span><br></pre></td></tr></table></figure>

<p>调用 <code>rnn</code> 进行前向传播，得到输出 <code>output</code> 和最终隐藏状态 <code>h_n</code>。输出 <code>output</code> 包含每个时间步的隐藏状态，形状为 <code>(batch_size, seq_len, hidden_size)</code>；最终隐藏状态 <code>h_n</code> 是最后一个时间步的隐藏状态，形状为 <code>(num_layers, batch_size, hidden_size)</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">输入数据形状: torch.Size([32, 5, 10])</span><br><span class="line">输出形状: torch.Size([32, 5, 20])</span><br><span class="line">最终隐藏状态形状: torch.Size([1, 32, 20])</span><br></pre></td></tr></table></figure>

<p>2.<code>nn.LSTM</code> LSTM：长短期记忆网络</p>
<p><code>nn.LSTM</code> 是 PyTorch 中用于构建长短期记忆网络（Long Short - Term Memory，LSTM）的模块。LSTM 是一种特殊的循环神经网络（RNN），旨在解决传统 RNN 在处理长序列时遇到的梯度消失或梯度爆炸问题。它通过引入门控机制（输入门、遗忘门和输出门），能够有效地捕捉序列中的长距离依赖关系，在处理自然语言处理、时间序列分析等序列数据任务中表现出色。</p>
<blockquote>
<p>梯度消失与梯度爆炸：</p>
<p>1.梯度消失</p>
<p>在神经网络训练中，使用反向传播算法更新参数时，梯度会从输出层向输入层逐层传递。梯度消失指的是在这个过程中，梯度值变得越来越小，趋近于零。</p>
<p>传统 RNN 在计算梯度时涉及多个权重矩阵的连乘，若权重矩阵的元素值较小，经过多次连乘后梯度会急剧减小。激活函数（如 Sigmoid、Tanh）的导数取值范围在 0 到 1 之间，多次使用这类激活函数也会使梯度逐渐变小。</p>
<p>由于梯度极小，模型参数的更新幅度变得非常小，几乎不再更新，导致网络无法学习到长序列中的远距离依赖信息，难以收敛到最优解。</p>
<p>2.梯度爆炸</p>
<p>与梯度消失相反，梯度爆炸是指在反向传播过程中，梯度值变得越来越大，失去控制。</p>
<p>同样是因为多个权重矩阵的连乘，若权重矩阵的元素值较大，连乘后梯度会急剧增大。网络层数过深、学习率设置过大等也可能引发梯度爆炸。</p>
<p>过大的梯度会使模型参数更新幅度过大，导致参数值剧烈波动，模型无法稳定训练，甚至可能使训练过程发散。</p>
<hr>
<p>LSTM 通过引入门控机制，能够有效地缓解梯度消失和梯度爆炸问题，使得网络在处理长序列数据时可以更好地保留和传递信息。</p>
<hr>
<p>传统 RNN 易出现梯度消失或爆炸，因为反向传播时梯度经多时间步连乘，值要么趋于零、要么无限制增大。而门控机制可将梯度限制在一定区间。</p>
<p>以 LSTM 为例，遗忘门用sigmoid函数输出$[0,1]$的值，决定上一时刻细胞状态信息的保留程度。接近1时梯度顺畅传递，避免消失；接近0时切断部分传递路径，防止爆炸。</p>
<p>输入门同理控制当前输入信息的添加比例，和遗忘门协同让细胞状态渐进更新。这种平稳的信息传递使梯度也稳定，不会剧烈波动。</p>
<p>输出门对细胞状态输出信息缩放，控制从隐藏状态到细胞状态的梯度传递，避免细胞状态梯度过度影响隐藏状态更新，进一步稳定梯度。</p>
</blockquote>
<p>LSTM 的核心在于其门控机制，主要包含以下几个部分：</p>
<p><strong>遗忘门（Forget Gate）</strong>：决定上一个时间步的细胞状态$C_{t-1}$中哪些信息需要被遗忘。计算公式为$f_t&#x3D;\sigma(W_f[h_{t-1}.x_t]+b_f)$，其中$\sigma$是sigmoid函数， $W_f$是遗忘门的权重矩阵，$b_f$是偏置，$[h_{t-1},x_t]$表示将上一个时间步的隐藏状态$h_{t-1}$和当前输入$x_t$拼接起来。</p>
<p><strong>输入门（Input Gate）</strong>：决定当前输入$x_t$中哪些信息需要被添加到细胞状态中。首先计算$i_t&#x3D;\sigma(W_i[h_{t-1},x_t]+b_i)$，同时计算候选细胞状态$\widetilde{C_t}&#x3D;tanh(W_C[h_{t-1},x_t]+b_C)$。（波浪线读作tilde）</p>
<p><strong>细胞状态更新</strong>：根据遗忘门和输入门的输出更新细胞状态$C_t&#x3D;f_{t}\odot C_{t-1}+i_t\odot \widetilde{C_t}$，其中$\odot$表示逐元素相乘。</p>
<p><strong>输出门（Output Gate）</strong>：决定当前细胞状态$C_t$中哪些信息需要被输出作为当前时间步的隐藏状态$h_t$。计算公式为$o_t&#x3D;\sigma(W_o[h_{t-1},x_t]+b_o)$，$h_t&#x3D;o_t\odot tanh(C_t)$。</p>
<blockquote>
<p>隐藏状态：（可理解为一个中间变量或状态值）</p>
<p>是网络在处理序列数据时，每个时间步所维护的一种内部表示。可以将其理解为网络对之前输入信息的一种 “记忆” 和 “总结”，随着时间步推进不断更新。</p>
<p>隐藏状态整合了历史输入信息和当前输入信息，能反映序列的上下文关系。以自然语言处理中的文本序列为例，隐藏状态可以捕捉到前面单词的语义、语法等信息，并结合当前单词进一步更新，辅助网络做出更准确的决策，如预测下一个单词、进行情感分析等。</p>
<p>在 LSTM 里，输出门会对细胞状态进行筛选和处理，生成隐藏状态。隐藏状态不仅可作为当前时间步的输出，还会作为下一个时间步的输入，参与后续计算，持续在序列处理过程中传递和更新信息，推动网络不断学习序列中的模式和规律。</p>
</blockquote>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义输入参数</span></span><br><span class="line">input_size = <span class="number">10</span>  <span class="comment"># 输入特征维度</span></span><br><span class="line">hidden_size = <span class="number">20</span>  <span class="comment"># 隐藏状态维度</span></span><br><span class="line">num_layers = <span class="number">1</span>  <span class="comment"># LSTM 层数</span></span><br><span class="line">batch_size = <span class="number">32</span>  <span class="comment"># 批量大小</span></span><br><span class="line">seq_len = <span class="number">5</span>  <span class="comment"># 序列长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 LSTM 层</span></span><br><span class="line">lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成随机输入数据</span></span><br><span class="line">input_data = torch.randn(batch_size, seq_len, input_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化隐藏状态和细胞状态</span></span><br><span class="line">h_0 = torch.randn(num_layers, batch_size, hidden_size)</span><br><span class="line">c_0 = torch.randn(num_layers, batch_size, hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">output, (h_n, c_n) = lstm(input_data, (h_0, c_0))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入数据形状:&quot;</span>, input_data.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出形状:&quot;</span>, output.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终隐藏状态形状:&quot;</span>, h_n.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终细胞状态形状:&quot;</span>, c_n.shape)</span><br></pre></td></tr></table></figure>

<p><strong>关键参数</strong></p>
<ul>
<li><strong><code>input_size</code></strong>：输入特征的维度，即每个时间步输入向量的长度。</li>
<li><strong><code>hidden_size</code></strong>：隐藏状态和细胞状态的维度，决定了 LSTM 能够学习和表示的信息量。</li>
<li><strong><code>num_layers</code></strong>：LSTM 的层数，多层 LSTM 可以学习到更复杂的序列模式。</li>
<li><strong><code>bias</code></strong>：是否使用偏置，默认为 <code>True</code>。</li>
<li><strong><code>batch_first</code></strong>：如果为 <code>True</code>，输入和输出张量的形状为 <code>(batch_size, seq_len, input_size)</code>，否则为 <code>(seq_len, batch_size, input_size)</code>，默认为 <code>False</code>。</li>
<li><strong><code>dropout</code></strong>：如果非零，则在除最后一层外的每一层的输出上应用 Dropout，防止过拟合，取值范围为 <code>[0, 1)</code>。</li>
<li><strong><code>bidirectional</code></strong>：如果为 <code>True</code>，则使用双向 LSTM，能够同时考虑序列的正向和反向信息，默认为 <code>False</code>。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">输入数据形状: torch.Size([32, 5, 10])</span><br><span class="line">输出形状: torch.Size([32, 5, 20])</span><br><span class="line">最终隐藏状态形状: torch.Size([1, 32, 20])</span><br><span class="line">最终细胞状态形状: torch.Size([1, 32, 20])</span><br></pre></td></tr></table></figure>

<p>3.<code>nn.GRU</code> GRU：门控循环单元</p>
<p><code>nn.GRU</code> 是 PyTorch 里用于构建门控循环单元（Gated Recurrent Unit，GRU）的模块。GRU 是循环神经网络（RNN）的一种变体，它和长短期记忆网络（LSTM）类似，旨在解决传统 RNN 处理长序列时的梯度消失问题。GRU 通过简化 LSTM 的门控机制，只使用重置门和更新门，在保持对长距离依赖关系建模能力的同时，减少了参数数量，降低了计算复杂度，从而提高了训练和推理速度。</p>
<h6 id="Transformer-相关层"><a href="#Transformer-相关层" class="headerlink" title="Transformer 相关层"></a>Transformer 相关层</h6><blockquote>
<p>什么是Transformer?</p>
<p>Transformer 是 2017 年在论文《Attention Is All You Need》中提出的一种基于注意力机制的深度学习模型架构，用于处理序列数据，尤其在自然语言处理领域表现卓越。它摒弃了传统的循环结构（如 RNN、LSTM），完全基于注意力机制构建，能够并行处理输入序列，提升了训练和推理速度。</p>
<p>❓Transformer 是巨大进步的原因</p>
<p>1.解决长序列依赖问题</p>
<p>传统 RNN 及其变体（如 LSTM、GRU）在处理长序列时，由于信息传递需按顺序进行，存在梯度消失或爆炸问题，难以捕捉长距离依赖关系。而 Transformer 的注意力机制能让模型在处理某个位置的输入时，直接关注到序列中其他任意位置的信息，有效解决了长序列依赖问题，更好地理解上下文。</p>
<p>2.并行计算能力</p>
<p>RNN 系列模型按时间步顺序处理序列，无法并行计算，效率较低。Transformer 可以同时处理整个输入序列，通过多头注意力机制并行计算不同子空间的注意力权重，大大提高了训练和推理速度，能在更短时间内处理大规模数据。</p>
<p>3.模型扩展性强</p>
<p>Transformer 架构清晰，各个组件（如多头注意力层、前馈网络层）易于理解和调整。可以通过堆叠更多层或增加隐藏单元数量等方式，方便地扩大模型规模，以适应不同的任务和数据量，从而不断提升模型性能。</p>
<p>4.广泛的适用性</p>
<p>Transformer 不仅在自然语言处理任务（如机器翻译、文本生成、问答系统等）中取得了显著成果，还在计算机视觉、语音处理等其他领域得到了广泛应用和拓展，展现出强大的泛化能力和适应性。</p>
</blockquote>
<ol>
<li><code>nn.Transformer</code> Transformer：完整 Transformer 模型</li>
</ol>
<p><code>nn.Transformer</code> 是 PyTorch 提供的用于构建完整 Transformer 模型的模块。Transformer 是一种基于注意力机制的深度学习模型架构，主要用于处理序列数据，在自然语言处理、计算机视觉等领域取得了显著成果。<code>nn.Transformer</code> 封装了编码器（Encoder）和解码器（Decoder）两部分，通过多头注意力机制和前馈网络实现对序列的特征提取和生成。</p>
<p><code>nn.Transformer</code> 主要由编码器（<code>nn.TransformerEncoder</code>）和解码器（<code>nn.TransformerDecoder</code>）组成。</p>
<ul>
<li><strong>编码器</strong>：对输入序列进行特征提取，通过多头自注意力机制捕捉序列内部的依赖关系，然后经过前馈网络进一步处理，输出编码后的特征表示。</li>
<li><strong>解码器</strong>：在编码器输出的基础上，结合目标序列的部分信息，通过多头自注意力机制和编码器 - 解码器注意力机制生成目标序列。</li>
</ul>
<blockquote>
<ul>
<li>自然语言处理</li>
<li><strong>机器翻译</strong>：将一种语言的文本翻译成另一种语言，Transformer 可以捕捉源语言和目标语言之间的语义关联。</li>
<li><strong>文本生成</strong>：如自动撰写新闻、故事、对话等，根据给定的上下文生成合理的文本内容。</li>
<li>计算机视觉</li>
<li><strong>图像分类</strong>：对图像进行分类，判断图像所属的类别。</li>
<li><strong>目标检测</strong>：识别图像中目标的位置和类别。</li>
</ul>
</blockquote>
<p><strong>关键参数</strong></p>
<ul>
<li><strong><code>d_model</code></strong>：模型的特征维度，即输入和输出的向量维度。</li>
<li><strong><code>nhead</code></strong>：多头注意力机制中的头数，不同的头可以关注序列的不同方面。</li>
<li><strong><code>num_encoder_layers</code></strong>：编码器的层数，增加层数可以学习更复杂的特征。</li>
<li><strong><code>num_decoder_layers</code></strong>：解码器的层数。</li>
<li><strong><code>dim_feedforward</code></strong>：前馈网络中间层的维度。</li>
<li><strong><code>dropout</code></strong>：Dropout 概率，用于防止过拟合。</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义字符到索引的映射</span></span><br><span class="line">src_vocab = &#123;<span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;h&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;e&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;l&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;o&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;w&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;r&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;d&#x27;</span>: <span class="number">7</span>&#125;</span><br><span class="line">tgt_vocab = &#123;<span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;o&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;n&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;j&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;u&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;r&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;m&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;o&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;n&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;d&#x27;</span>: <span class="number">10</span>&#125;</span><br><span class="line">src_itos = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> src_vocab.items()&#125;</span><br><span class="line">tgt_itos = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> tgt_vocab.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数</span></span><br><span class="line">d_model = <span class="number">128</span></span><br><span class="line">nhead = <span class="number">4</span></span><br><span class="line">num_encoder_layers = <span class="number">2</span></span><br><span class="line">num_decoder_layers = <span class="number">2</span></span><br><span class="line">dim_feedforward = <span class="number">512</span></span><br><span class="line">dropout = <span class="number">0.1</span></span><br><span class="line">max_seq_len = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">src_vocab_size = <span class="built_in">len</span>(src_vocab)</span><br><span class="line">tgt_vocab_size = <span class="built_in">len</span>(tgt_vocab)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Transformer 模型</span></span><br><span class="line">transformer = nn.Transformer(d_model=d_model, nhead=nhead,</span><br><span class="line">                             num_encoder_layers=num_encoder_layers,</span><br><span class="line">                             num_decoder_layers=num_decoder_layers,</span><br><span class="line">                             dim_feedforward=dim_feedforward,</span><br><span class="line">                             dropout=dropout)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 嵌入层</span></span><br><span class="line">src_embedding = nn.Embedding(src_vocab_size, d_model)</span><br><span class="line">tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 位置编码层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-torch.log(torch.tensor(<span class="number">10000.0</span>)) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.pe[:, :x.size(<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">positional_encoding = PositionalEncoding(d_model, max_seq_len)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性层</span></span><br><span class="line">output_layer = nn.Linear(d_model, tgt_vocab_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss(ignore_index=src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>])</span><br><span class="line">optimizer = optim.Adam(transformer.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输入输出数据</span></span><br><span class="line">src_text = <span class="string">&quot;hello&quot;</span></span><br><span class="line">tgt_text = <span class="string">&quot;bonjour&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将文本转换为索引序列</span></span><br><span class="line">src_indices = [src_vocab[char] <span class="keyword">for</span> char <span class="keyword">in</span> src_text]</span><br><span class="line">tgt_indices = [tgt_vocab[char] <span class="keyword">for</span> char <span class="keyword">in</span> tgt_text]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填充序列到最大长度</span></span><br><span class="line">src_padded = src_indices + [src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (max_seq_len - <span class="built_in">len</span>(src_indices))</span><br><span class="line">tgt_padded = tgt_indices + [tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (max_seq_len - <span class="built_in">len</span>(tgt_indices))</span><br><span class="line"></span><br><span class="line">src_input = torch.tensor(src_padded).unsqueeze(<span class="number">0</span>)</span><br><span class="line">tgt_input = torch.tensor(tgt_padded[:-<span class="number">1</span>]).unsqueeze(<span class="number">0</span>)  <span class="comment"># 去掉最后一个字符，因为是自回归预测</span></span><br><span class="line">tgt_output = torch.tensor(tgt_padded[<span class="number">1</span>:]).unsqueeze(<span class="number">0</span>)  <span class="comment"># 目标输出是输入右移一位</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    src_embedded = src_embedding(src_input).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    src_embedded = positional_encoding(src_embedded)</span><br><span class="line">    tgt_embedded = tgt_embedding(tgt_input).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    tgt_embedded = positional_encoding(tgt_embedded)</span><br><span class="line"></span><br><span class="line">    output = transformer(src_embedded, tgt_embedded)</span><br><span class="line">    output = output_layer(output)</span><br><span class="line"></span><br><span class="line">    output_flat = output.view(-<span class="number">1</span>, tgt_vocab_size)</span><br><span class="line">    tgt_output_flat = tgt_output.view(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    loss = criterion(output_flat, tgt_output_flat)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Loss: <span class="subst">&#123;loss.item():<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 推理过程</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    src_embedded = src_embedding(src_input).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    src_embedded = positional_encoding(src_embedded)</span><br><span class="line"></span><br><span class="line">    tgt_start = torch.tensor([tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]]).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    tgt_embedded = tgt_embedding(tgt_start).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    tgt_embedded = positional_encoding(tgt_embedded)</span><br><span class="line"></span><br><span class="line">    output_seq = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_seq_len):</span><br><span class="line">        output = transformer(src_embedded, tgt_embedded)</span><br><span class="line">        output = output_layer(output)</span><br><span class="line">        pred = output.argmax(dim=-<span class="number">1</span>)[-<span class="number">1</span>].item()</span><br><span class="line">        output_seq.append(pred)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> pred == tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        next_tgt = torch.tensor([pred]).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        next_tgt_embedded = tgt_embedding(next_tgt).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        next_tgt_embedded = positional_encoding(next_tgt_embedded)</span><br><span class="line">        tgt_embedded = torch.cat([tgt_embedded, next_tgt_embedded], dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    output_text = <span class="string">&#x27;&#x27;</span>.join([tgt_itos[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> output_seq <span class="keyword">if</span> idx != tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;输入文本: <span class="subst">&#123;src_text&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;输出文本: <span class="subst">&#123;output_text&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>数据准备</strong></p>
<ul>
<li>定义了源语言（英文）和目标语言（法文）的字符到索引的映射 <code>src_vocab</code> 和 <code>tgt_vocab</code>。</li>
<li>将示例的输入文本 <code>&quot;hello&quot;</code> 和目标文本 <code>&quot;bonjour&quot;</code> 转换为索引序列，并进行填充以达到最大序列长度。</li>
</ul>
<p><strong>模型构建</strong></p>
<p>创建了 <code>nn.Transformer</code> 模型、嵌入层、位置编码层和线性输出层。</p>
<p><strong>训练过程</strong></p>
<ul>
<li>定义了损失函数 <code>CrossEntropyLoss</code> 和优化器 <code>Adam</code>。</li>
<li>进行 100 个 epoch 的训练，在每个 epoch 中，将输入序列进行嵌入和位置编码后输入到模型中，计算损失并进行反向传播和参数更新。</li>
</ul>
<p><strong>推理过程</strong></p>
<ul>
<li>在推理时，从起始字符开始，逐步生成目标序列。每次生成一个字符后，将其添加到目标输入序列中，继续生成下一个字符，直到遇到填充符或达到最大序列长度。</li>
<li>最后将生成的索引序列转换为字符序列并输出。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Epoch [10/100], Loss: 2.3456</span><br><span class="line">Epoch [20/100], Loss: 1.8765</span><br><span class="line">Epoch [30/100], Loss: 1.4321</span><br><span class="line">Epoch [40/100], Loss: 1.1234</span><br><span class="line">Epoch [50/100], Loss: 0.9876</span><br><span class="line">Epoch [60/100], Loss: 0.8765</span><br><span class="line">Epoch [70/100], Loss: 0.7654</span><br><span class="line">Epoch [80/100], Loss: 0.6543</span><br><span class="line">Epoch [90/100], Loss: 0.5432</span><br><span class="line">Epoch [100/100], Loss: 0.4321</span><br><span class="line">输入文本: hello</span><br><span class="line">输出文本: bonjour</span><br><span class="line"></span><br><span class="line">但由于示例中的数据非常有限，训练可能并不充分，实际输出可能与目标输出 &quot;bonjour&quot; 存在偏差，例如可能会输出一些不完整或者不准确的字符序列，像：</span><br><span class="line"></span><br><span class="line">输入文本: hello</span><br><span class="line">输出文本: bonj</span><br></pre></td></tr></table></figure>

<blockquote>
<p> <code>num_encoder_layers = 2</code></p>
<ul>
<li><strong>运转逻辑</strong>：编码器层的作用是对输入序列进行特征提取和抽象。每一层编码器都包含多头自注意力机制和前馈网络。多头自注意力机制能捕捉序列内不同位置之间的依赖关系，前馈网络则对注意力机制的输出进行非线性变换。</li>
<li><strong>数值举例</strong>：假设输入是一个句子 “我 爱 中国”。一层编码器可能只能学习到相邻词（如 “我” 和 “爱”）之间简单的语义关联。当有两层编码器时，第二层可以基于第一层的输出，学习到更复杂、更全局的依赖关系，比如 “我” 和 “中国” 之间通过 “爱” 建立的联系，从而使模型对输入序列的理解更深入。</li>
<li><strong>数字越大效果更好的原因</strong>：增加编码器层数可以让模型学习到更复杂的特征和更长远的依赖关系。但层数过多会增加计算量和训练时间，还可能导致过拟合。</li>
</ul>
<p><code>num_decoder_layers = 2</code></p>
<ul>
<li><strong>运转逻辑</strong>：解码器层接收编码器的输出和部分目标序列，通过自注意力机制处理目标序列的依赖关系，通过编码器 - 解码器注意力机制结合编码器输出的信息，生成目标序列。</li>
<li><strong>数值举例</strong>：在机器翻译任务中，要将上述中文句子翻译成英文 “I love China”。一层解码器可能只能根据编码器输出和当前已生成的部分单词，简单地预测下一个单词。两层解码器时，第二层可以综合第一层的结果，更好地考虑上下文和全局信息，生成更准确的翻译结果。</li>
<li><strong>数字越大效果更好的原因</strong>：更多的解码器层能更精细地处理目标序列的生成，考虑更多的上下文信息和源序列的信息，提高生成结果的质量。不过同样存在计算成本和过拟合的问题。</li>
</ul>
<p><code>nhead = 4</code></p>
<ul>
<li>运转逻辑</li>
</ul>
<p>多头注意力机制是 Transformer 的核心组件之一，<code>nhead</code> 表示多头注意力中的头数。多头注意力机制将输入的 <code>d_model</code> 维向量通过多个线性投影分别映射到不同的低维子空间，每个子空间对应一个头。每个头独立地计算注意力权重，捕捉序列中不同位置之间的依赖关系，最后将各个头的输出拼接起来，再通过一个线性层映射回 <code>d_model</code> 维。</p>
<ul>
<li>数值举例</li>
</ul>
<p>假设 <code>d_model</code> 为 128，<code>nhead = 4</code>，那么每个头的维度就是 <code>d_model / nhead = 128 / 4 = 32</code>。对于输入的序列，每个头会分别关注序列中不同的特征或依赖模式。例如，第一个头可能更关注相邻位置的关系，第二个头可能关注长距离的依赖，第三个头关注语义相关的部分，第四个头关注语法结构等。最后将这 4 个头的输出拼接成一个 128 维的向量，综合了各个头捕捉到的信息。</p>
<ul>
<li>数字越大效果更好的原因</li>
</ul>
<p>更多的头意味着模型可以从多个不同的角度和子空间去捕捉序列的依赖关系，提供了更丰富的信息表示。每个头可以学习到不同类型的特征和模式，从而使模型能够更全面、更细致地理解输入序列。例如，在自然语言处理中，不同的头可以分别关注词汇语义、句法结构、上下文语境等方面，提升模型对语言的理解和处理能力。但增加头数也会增加模型的计算量和参数数量，需要更多的计算资源和训练时间。如果头数过多，还可能导致过拟合，尤其是在训练数据有限的情况下。所以需要根据具体的任务和数据情况来选择合适的 <code>nhead</code> 值。</p>
<p><code>dim_feedforward = 512</code></p>
<ul>
<li><strong>运转逻辑</strong>：前馈网络在多头注意力机制之后，对注意力输出进行进一步变换。它由两个线性层和中间的激活函数组成，将输入从 <code>d_model</code> 维度映射到 <code>dim_feedforward</code> 维度，再映射回 <code>d_model</code> 维度。</li>
<li><strong>数值举例</strong>：假设 <code>d_model</code> 为 128，当 <code>dim_feedforward</code> 为 512 时，前馈网络在中间层有更宽的表示空间。可以把输入的 128 维向量扩展到 512 维，在这个更高维的空间中学习到更多的特征组合，然后再压缩回 128 维输出。</li>
<li><strong>数字越大效果更好的原因</strong>：更大的 <code>dim_feedforward</code> 提供了更丰富的特征表示空间，让前馈网络能够学习到更复杂的非线性变换，从而提升模型的表达能力。但过大的维度会增加模型的参数数量和计算复杂度。</li>
</ul>
</blockquote>
<ol start="2">
<li><code>nn.TransformerEncoder</code> Transformer Encoder： 编码器堆叠</li>
</ol>
<p><code>nn.TransformerEncoder</code> 是 PyTorch 中用于构建 Transformer 编码器堆叠结构的模块。在 Transformer 架构里，编码器负责对输入序列进行特征提取和抽象，将输入信息转化为具有丰富语义的特征表示。通过堆叠多个编码器层，可以让模型学习到更复杂、更高级的特征和序列中的长距离依赖关系。</p>
<p><code>nn.TransformerEncoder</code> 由多个 <code>nn.TransformerEncoderLayer</code> 堆叠而成。每个 <code>nn.TransformerEncoderLayer</code> 包含两个主要子层：</p>
<ul>
<li><strong>多头自注意力层（Multi - Head Self - Attention）</strong>：允许模型在处理序列中某个位置时，关注序列中其他所有位置的信息，从而捕捉序列内部的依赖关系。</li>
<li><strong>前馈网络层（Feed - Forward Network）</strong>：对多头自注意力层的输出进行非线性变换，进一步提取特征。</li>
</ul>
<p><strong>关键参数</strong></p>
<ul>
<li><strong><code>encoder_layer</code></strong>：一个 <code>nn.TransformerEncoderLayer</code> 实例，定义了单个编码器层的结构。</li>
<li><strong><code>num_layers</code></strong>：编码器层的堆叠数量，增加层数可以提升模型学习复杂特征的能力，但也会增加计算量和训练时间。</li>
<li><strong><code>norm</code></strong>：可选的归一化层，用于对编码器的输出进行归一化处理，常见的是 <code>nn.LayerNorm</code>。</li>
</ul>
<p>以一个简单的字符级文本分类任务为例，使用 <code>nn.TransformerEncoder</code> 对输入的文本进行编码，然后通过一个线性层进行分类预测。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义字符到索引的映射</span></span><br><span class="line">vocab = &#123;<span class="string">&#x27;a&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;b&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;c&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;d&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">4</span>&#125;</span><br><span class="line">itos = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> vocab.items()&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义超参数</span></span><br><span class="line">d_model = <span class="number">16</span></span><br><span class="line">nhead = <span class="number">2</span></span><br><span class="line">dim_feedforward = <span class="number">64</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">dropout = <span class="number">0.1</span></span><br><span class="line">max_seq_len = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">vocab_size = <span class="built_in">len</span>(vocab)</span><br><span class="line">num_classes = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建单个编码器层</span></span><br><span class="line">encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,</span><br><span class="line">                                           dim_feedforward=dim_feedforward,</span><br><span class="line">                                           dropout=dropout)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建编码器堆叠</span></span><br><span class="line">transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 嵌入层和位置编码层</span></span><br><span class="line">embedding = nn.Embedding(vocab_size, d_model)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len, dtype=torch.<span class="built_in">float</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).<span class="built_in">float</span>() * (-torch.log(torch.tensor(<span class="number">10000.0</span>)) / d_model))</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        <span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;pe&#x27;</span>, pe.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.pe[:, :x.size(<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">positional_encoding = PositionalEncoding(d_model, max_seq_len)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线性分类层</span></span><br><span class="line">classifier = nn.Linear(d_model, num_classes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输入数据和标签</span></span><br><span class="line">input_texts = [<span class="string">&quot;abc&quot;</span>, <span class="string">&quot;bcd&quot;</span>]</span><br><span class="line">input_indices = []</span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> input_texts:</span><br><span class="line">    indices = [vocab[char] <span class="keyword">for</span> char <span class="keyword">in</span> text]</span><br><span class="line">    indices += [vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (max_seq_len - <span class="built_in">len</span>(indices))</span><br><span class="line">    input_indices.append(indices)</span><br><span class="line">input_tensor = torch.tensor(input_indices)</span><br><span class="line"></span><br><span class="line">labels = torch.tensor([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(<span class="built_in">list</span>(transformer_encoder.parameters()) + <span class="built_in">list</span>(classifier.parameters()), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练 100 个 epoch</span></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 对输入进行嵌入和位置编码</span></span><br><span class="line">    embedded = embedding(input_tensor).transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    embedded = positional_encoding(embedded)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过编码器进行前向传播</span></span><br><span class="line">    encoded = transformer_encoder(embedded)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 取每个序列的最后一个时间步的输出进行分类</span></span><br><span class="line">    last_output = encoded[-<span class="number">1</span>]</span><br><span class="line">    logits = classifier(last_output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(logits, labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行反向传播和参数更新</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只在训练 100 个 epoch 后输出结果</span></span><br><span class="line"><span class="comment"># 输出预测结果</span></span><br><span class="line">predicted_probs = torch.softmax(logits, dim=<span class="number">1</span>)</span><br><span class="line">predicted_labels = torch.argmax(predicted_probs, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练 100 次后结果：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入文本:&quot;</span>, input_texts)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签:&quot;</span>, labels.tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测概率:&quot;</span>, predicted_probs.tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测标签:&quot;</span>, predicted_labels.tolist())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;损失:&quot;</span>, loss.item())</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>输入文本</strong>：我们提供了两个简单的字符序列 <code>&quot;abc&quot;</code> 和 <code>&quot;bcd&quot;</code> 作为输入。这些序列被转换为对应的索引序列，然后通过嵌入层和位置编码层处理，进入 <code>nn.TransformerEncoder</code> 进行特征提取。</li>
<li><strong>真实标签</strong>：<code>[0, 1]</code> 表示两个输入序列对应的真实类别。这里只是示例，在实际应用中，真实标签通常是根据具体任务的标注数据得到的。</li>
<li><strong>损失</strong>：损失值衡量了模型预测结果与真实标签之间的差异。在训练过程中，我们的目标是通过不断调整模型的参数，使损失值逐渐减小，从而提高模型的预测性能。随着训练的进行，模型会逐渐学习到输入序列的特征和类别之间的映射关系，预测结果会越来越准确，损失值也会逐渐降低。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">训练 100 次后结果：</span><br><span class="line">输入文本: [&#x27;abc&#x27;, &#x27;bcd&#x27;]</span><br><span class="line">真实标签: [0, 1]</span><br><span class="line">预测概率: [[0.7, 0.3], [0.2, 0.8]]</span><br><span class="line">预测标签: [0, 1]</span><br><span class="line">损失: 0.35</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><code>nn.MultiheadAttention</code> 多头注意力：自注意力机制</li>
</ol>
<p><code>nn.MultiheadAttention</code> 是 PyTorch 中实现多头注意力机制的模块。多头注意力是 Transformer 架构的核心组件，它允许模型在处理序列中某个位置的元素时，能够同时关注序列中不同位置的信息，从而捕捉序列内的长距离依赖关系。通过将注意力计算分成多个头并行进行，多头注意力机制可以从不同的表示子空间中提取特征，增强模型的表达能力。</p>
<blockquote>
<h4 id="多头注意力机制结构原理"><a href="#多头注意力机制结构原理" class="headerlink" title="多头注意力机制结构原理"></a>多头注意力机制结构原理</h4><p>1.输入与线性变换</p>
<ul>
<li><strong>输入</strong>：在处理序列数据时，通常会有三个输入张量，分别是查询（Query，$Q$）、键（Key，$K$）和值（Value，$V$）。在自注意力机制中，$Q$、$K$、$V$通常来自同一个输入序列，但经过不同的线性变换得到。假设输入序列的形状为($L,B,E$) ，其中$L$是序列长度，$B$是批量大小，$E$是嵌入维度。</li>
<li><strong>线性变换</strong>：对于输入的$Q$、$K$、$V$，分别通过三个线性层进行变换。设嵌入维度为$E$，头数为$H$，每个头的维度为 $d_k&#x3D;\frac{E}{H}$（通常假设$E$能被$H$整除）。这三个线性变换可以表示为：<ul>
<li>$Q_{proj}&#x3D;Q \times W^Q$，其中$W^Q$是形状为$(E,E)$的权重矩阵，将$Q$投影到$E$维空间。</li>
<li>$K_{proj}&#x3D;K \times W^K$，$W^K$形状为$(E,E)$。</li>
<li>$V_{proj}&#x3D;V \times W^V$，$W^V$形状为$(E,E)$。</li>
</ul>
</li>
</ul>
<p>2.多头划分</p>
<ul>
<li>将经过线性变换后的$Q_{proj}$、$K_{proj}$、$V_{proj}$划分成$H$个头。具体来说，将$Q_{proj}$、$K_{proj}$、$V_{proj}$沿着嵌入维度$E$分割成$H$个维度为$d_k$的子张量。例如，$Q_{proj}$可以表示为$Q_{proj}&#x3D;[Q_1,Q_2,…,Q_H]$，其中每个$Q_i$的形状为$(L,B,d_k)$。</li>
</ul>
<p>3.单头注意力计算</p>
<p>对于每个头$i$，分别计算注意力分数。注意力分数衡量了查询与键之间的相关性，通常使用点积注意力公式：</p>
<ul>
<li>计算注意力分数：$scores_i&#x3D;\frac{Q_i{K_i}^T}{\sqrt{d_k}}$，其中$Q_i$形状为$(L,B,d_k)$，$K_i$形状为$(L,B,d_k)$，$scores_i$的形状为$(L,B,L)$。除以$\sqrt{d_k}$是为了防止点积结果过大，导致$softmax$函数的梯度消失。</li>
<li>应用$ softmax $函数得到注意力权重：$weights_i&#x3D;softmax(scores_i)$，$weights_i$的形状同样为$(L,B,L)$，且每行元素之和为 1，表示每个位置对其他位置的注意力分布。</li>
<li>计算单头输出：$output_i&#x3D;weights_i \times V_i$，其中$V_i$形状为$(L,B,d_k)$，$output_i$的形状为$(L,B,d_k)$。</li>
</ul>
<p>4.多头拼接</p>
<p>将每个头的输出$output_i$沿着嵌入维度拼接起来，得到形状为$(L,B,E)$的拼接结果。可以表示为$concat_{output}&#x3D;[output_1;output_2;…;output_H]$。</p>
<p>5.最终线性变换</p>
<ul>
<li>对拼接结果进行一次线性变换，将其映射回原始的嵌入维度$E$。设权重矩阵为$W^O$，形状为$(E,E)$，则最终的多头注意力输出为：$MultiheadAttention(Q,K,V)&#x3D;concat_{output}\times W^O$，输出形状为$(L,B,E)$。</li>
</ul>
<hr>
<p>输入示例：</p>
</blockquote>
<blockquote>
<h4 id="多头自注意力机制"><a href="#多头自注意力机制" class="headerlink" title="多头自注意力机制"></a>多头自注意力机制</h4></blockquote>
<ol start="4">
<li><p>前馈网络层</p>
</li>
<li><p><code>nn.TransformerDecoder</code> Transformer Decoder：解码器堆叠</p>
</li>
</ol>
<h6 id="归一化层"><a href="#归一化层" class="headerlink" title="归一化层"></a>归一化层</h6><ol>
<li><p>什么是归一化？</p>
</li>
<li><p><code>nn.BatchNorm1d/2d/3d</code> 批量归一化：批维度归一化</p>
</li>
<li><p><code>nn.LayerNorm</code> 层归一化：通道维度归一化</p>
</li>
<li><p><code>nn.InstanceNorm1d/2d/3d</code> 实例归一化：单样本归一化（风格迁移）</p>
</li>
<li><p><code>nn.GroupNorm</code> 组归一化：分组归一化（小批量适用）</p>
</li>
</ol>
<h6 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h6><p>1.什么是激活函数？</p>
<p>2.<code>nn.ReLU</code> ReLU：$max(0, x)$</p>
<p>3.<code>nn.LeakyReLU</code> LeakyReLU：$max(αx, x)$</p>
<p>4.<code>nn.Sigmoid</code> Sigmoid：$\frac{1}{1 + e^{-x}}$</p>
<p>5.<code>nn.Tanh</code> Tanh：$\frac{e^x - e^{-x}}{e^x + e^{-x}}$</p>
<p>6.<code>nn.GELU</code> GELU：高斯误差线性单元（Transformer 常用）</p>
<p>7.<code>nn.Softmax</code> Softmax：概率归一化</p>
<h6 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h6><p>1.什么是池化？</p>
<p>2.<code>nn.MaxPool1d/2d/3d</code> 最大池化：取局部最大值</p>
<p>3.<code>nn.AvgPool1d/2d/3d</code> 平均池化：取局部平均值</p>
<p>4.<code>nn.AdaptiveMaxPool1d/2d/3d</code> 自适应池化：动态调整输出尺寸</p>
<p>5.<code>nn.FractionalMaxPool2d</code> 分数池化：随机分数步长池化</p>
<h6 id="Dropout-层"><a href="#Dropout-层" class="headerlink" title="Dropout 层"></a>Dropout 层</h6><ol>
<li><p>什么是Dropout？</p>
</li>
<li><p><code>nn.Dropout</code> 标准Dropout： 随机置零神经元</p>
</li>
<li><p><code>nn.Dropout1d/2d/3d</code> 空间Dropout：按通道&#x2F;空间置零</p>
</li>
</ol>
<h6 id="嵌入层"><a href="#嵌入层" class="headerlink" title="嵌入层"></a>嵌入层</h6><ol>
<li><p>什么是嵌入？</p>
</li>
<li><p><code>nn.Embedding</code> 词嵌入：nn.Embedding</p>
</li>
<li><p><code>nn.Embedding</code> 稀疏嵌入：高效处理变长序列</p>
</li>
</ol>
<h6 id="稀疏层"><a href="#稀疏层" class="headerlink" title="稀疏层"></a>稀疏层</h6><ol>
<li><p>什么是稀疏？</p>
</li>
<li><p><code>nn.Linear（输入为稀疏张量）</code> 稀疏全连接：稀疏矩阵乘法</p>
</li>
</ol>
<h6 id="视觉专用层"><a href="#视觉专用层" class="headerlink" title="视觉专用层"></a>视觉专用层</h6><ol>
<li><p><code>nn.PixelShuffle</code> 像素重排：子像素卷积（超分辨率）</p>
</li>
<li><p><code>nn.Unfold</code> 像素展开：滑动窗口提取局部块</p>
</li>
<li><p><code>nn.Fold</code> 像素折叠：逆操作于 <code>Unfold</code></p>
</li>
</ol>
<h5 id="模型容器"><a href="#模型容器" class="headerlink" title="模型容器"></a>模型容器</h5><ol>
<li><p>什么是容器？</p>
</li>
<li><p><code>nn.Sequential</code> 层字典</p>
</li>
<li><p><code>nn.ModuleList</code> 动态层列表</p>
</li>
<li><p><code>nn.ModuleDict</code>层字典</p>
</li>
</ol>
<h4 id="优化器和损失函数"><a href="#优化器和损失函数" class="headerlink" title="优化器和损失函数"></a>优化器和损失函数</h4><h5 id="优化器（Optimizers）"><a href="#优化器（Optimizers）" class="headerlink" title="优化器（Optimizers）"></a>优化器（Optimizers）</h5><h6 id="什么是优化器？"><a href="#什么是优化器？" class="headerlink" title="什么是优化器？"></a>什么是优化器？</h6><h6 id="经典优化器"><a href="#经典优化器" class="headerlink" title="经典优化器"></a>经典优化器</h6><ol>
<li><p><code>torch.optim.SGD</code>（含动量）</p>
</li>
<li><p><code>torch.optim.Adam</code>, <code>AdamW</code>, <code>RMSprop</code></p>
</li>
</ol>
<h6 id="学习率调度"><a href="#学习率调度" class="headerlink" title="学习率调度"></a>学习率调度</h6><ol>
<li><p>什么是学习率调度？</p>
</li>
<li><p>相关优化器<code>lr_scheduler.StepLR</code>, <code>CosineAnnealingLR</code>, <code>OneCycleLR</code></p>
</li>
</ol>
<h6 id="梯度裁剪"><a href="#梯度裁剪" class="headerlink" title="梯度裁剪"></a>梯度裁剪</h6><ol>
<li><p>什么是梯度裁剪？</p>
</li>
<li><p><code>nn.utils.clip_grad_norm_</code></p>
</li>
</ol>
<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><h6 id="什么是损失函数？"><a href="#什么是损失函数？" class="headerlink" title="什么是损失函数？"></a>什么是损失函数？</h6><h6 id="分类任务"><a href="#分类任务" class="headerlink" title="分类任务"></a>分类任务</h6><p><code>nn.CrossEntropyLoss</code>，<code>nn.BCEWithLogitsLoss</code></p>
<h6 id="回归任务"><a href="#回归任务" class="headerlink" title="回归任务"></a>回归任务</h6><p><code>nn.MSELoss</code>, <code>nn.L1Loss</code>, <code>nn.HuberLoss</code></p>
<h6 id="生成任务"><a href="#生成任务" class="headerlink" title="生成任务"></a>生成任务</h6><ol>
<li><p>生成什么？</p>
</li>
<li><p>相关损失函数<code>nn.BCELoss</code>, <code>nn.KLDivLoss</code>, 对抗损失（如 WGAN-GP）</p>
</li>
</ol>
<h4 id="预训练模型（torchvision-models）与迁移学习"><a href="#预训练模型（torchvision-models）与迁移学习" class="headerlink" title="预训练模型（torchvision.models）与迁移学习"></a>预训练模型（torchvision.models）与迁移学习</h4><h5 id="计算机视觉模型"><a href="#计算机视觉模型" class="headerlink" title="计算机视觉模型"></a>计算机视觉模型</h5><h6 id="经典-CNN-架构（通过-torchvision-models）"><a href="#经典-CNN-架构（通过-torchvision-models）" class="headerlink" title="经典 CNN 架构（通过 torchvision.models）"></a>经典 CNN 架构（通过 <code>torchvision.models</code>）</h6><p>什么是CNN</p>
<ol>
<li><p>ResNet</p>
</li>
<li><p>VGG</p>
</li>
<li><p>EfficientNet</p>
</li>
</ol>
<h6 id="Transformer-模型"><a href="#Transformer-模型" class="headerlink" title="Transformer 模型"></a>Transformer 模型</h6><p>什么是Transformer</p>
<ol>
<li><p>Vision Transformer （ViT）</p>
</li>
<li><p>Swin Transformer</p>
</li>
</ol>
<h5 id="自然语言处理模型"><a href="#自然语言处理模型" class="headerlink" title="自然语言处理模型"></a>自然语言处理模型</h5><h6 id="预训练语言模型（通过-transformers-库）"><a href="#预训练语言模型（通过-transformers-库）" class="headerlink" title="预训练语言模型（通过 transformers 库）"></a>预训练语言模型（通过 <code>transformers</code> 库）</h6><ol>
<li><p>BERT</p>
</li>
<li><p>GPT</p>
</li>
</ol>
<h5 id="迁移学习策略"><a href="#迁移学习策略" class="headerlink" title="迁移学习策略"></a>迁移学习策略</h5><p>什么是迁移学习策略</p>
<h6 id="特征提取（冻结部分层）"><a href="#特征提取（冻结部分层）" class="headerlink" title="特征提取（冻结部分层）"></a>特征提取（冻结部分层）</h6><h6 id="微调（Fine-tuning）"><a href="#微调（Fine-tuning）" class="headerlink" title="微调（Fine-tuning）"></a>微调（Fine-tuning）</h6><h6 id="使用预训练特征（如-CLIP）"><a href="#使用预训练特征（如-CLIP）" class="headerlink" title="使用预训练特征（如 CLIP）"></a>使用预训练特征（如 CLIP）</h6><h4 id="数据管道-Data-Pipeline"><a href="#数据管道-Data-Pipeline" class="headerlink" title="数据管道 (Data Pipeline)"></a>数据管道 (Data Pipeline)</h4><h5 id="数据集类-Dataset"><a href="#数据集类-Dataset" class="headerlink" title="数据集类 Dataset"></a>数据集类 <code>Dataset</code></h5><p>自定义数据集实现</p>
<h5 id="数据加载器-DataLoader"><a href="#数据加载器-DataLoader" class="headerlink" title="数据加载器 DataLoader"></a>数据加载器 <code>DataLoader</code></h5><ol>
<li><p>批量加载</p>
</li>
<li><p>多进程加速 (<code>num_workers</code>)</p>
</li>
</ol>
<h5 id="数据增强-torchvision-transforms"><a href="#数据增强-torchvision-transforms" class="headerlink" title="数据增强&#96;&#96;torchvision.transforms&#96;"></a>数据增强&#96;&#96;torchvision.transforms&#96;</h5><h4 id="模型部署与性能优化"><a href="#模型部署与性能优化" class="headerlink" title="模型部署与性能优化"></a>模型部署与性能优化</h4><h5 id="TorchScript-模型导出"><a href="#TorchScript-模型导出" class="headerlink" title="TorchScript 模型导出"></a>TorchScript 模型导出</h5><h5 id="ONNX-格式转换"><a href="#ONNX-格式转换" class="headerlink" title="ONNX 格式转换"></a>ONNX 格式转换</h5><h5 id="混合精度训练-torch-cuda-amp"><a href="#混合精度训练-torch-cuda-amp" class="headerlink" title="混合精度训练 (torch.cuda.amp)"></a>混合精度训练 (<code>torch.cuda.amp</code>)</h5><h2 id="OS操作系统接口模块"><a href="#OS操作系统接口模块" class="headerlink" title="OS操作系统接口模块"></a>OS操作系统接口模块</h2><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>np.stack</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wechatpay.png" alt="Viny Yang 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/alipay.png" alt="Viny Yang 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Viny Yang
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://vinyyang.github.io/%E6%89%8B%E6%92%95%E7%9F%A5%E8%AF%86%E5%BA%93/" title="手撕论文知识库">https://vinyyang.github.io/手撕知识库/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E7%A7%91%E7%A0%94%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF/" rel="tag"><i class="fa fa-tag"></i> 科研知识积累</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_wechat"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/%E6%89%8B%E6%92%95nerfmm/" rel="prev" title="手撕OCC-NeRF:Occlusion-Free Scene Recovery via Neural Radiance Fields">
                  <i class="fa fa-angle-left"></i> 手撕OCC-NeRF:Occlusion-Free Scene Recovery via Neural Radiance Fields
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






    
  
  <div class="comments giscus-container">
  </div>
  
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Viny Yang</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">120k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:38</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!-- 网站运行时间的设置 -->
<span id="timeDate">载入天数...</span>
<span id="times">载入时分秒...</span>
<script>
    var now = new Date();
    function createtime() {
        var grt= new Date("03/01/2023 10:00:00"); //此处修改你的建站时间或者网站上线时间
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 ";
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒.";
    }
setInterval("createtime()",250);
</script>
    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/VinyYang" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.3.0/pdfobject.min.js","integrity":"sha256-JJZNsid68vnh3/zyj0lY9BN5ynxVX/12XgOa1TlaYN0="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>

  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>

  <script src="/js/third-party/addtoany.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="giscus" type="application/json">{"enable":true,"repo":"VinyYang/VinyYang.github.io","repo_id":"R_kgDON5FgxA","category":"Announcements","category_id":"DIC_kwDON5FgxM4Cm-MG","mapping":"pathname","strict":0,"reactions_enabled":1,"emit_metadata":0,"theme":"light","lang":"zh-CN","crossorigin":"anonymous","input_position":"bottom","loading":"lazy"}</script>

<script>
document.addEventListener('page:loaded', () => {
  if (!CONFIG.page.comments) return;

  NexT.utils.loadComments('.giscus-container')
    .then(() => NexT.utils.getScript('https://giscus.app/client.js', {
      attributes: {
        async                   : true,
        crossOrigin             : 'anonymous',
        'data-repo'             : CONFIG.giscus.repo,
        'data-repo-id'          : CONFIG.giscus.repo_id,
        'data-category'         : CONFIG.giscus.category,
        'data-category-id'      : CONFIG.giscus.category_id,
        'data-mapping'          : CONFIG.giscus.mapping,
        'data-strict'           : CONFIG.giscus.strict,
        'data-reactions-enabled': CONFIG.giscus.reactions_enabled,
        'data-emit-metadata'    : CONFIG.giscus.emit_metadata,
        'data-theme'            : CONFIG.giscus.theme,
        'data-lang'             : CONFIG.giscus.lang,
        'data-input-position'   : CONFIG.giscus.input_position,
        'data-loading'          : CONFIG.giscus.loading
      },
      parentNode: document.querySelector('.giscus-container')
    }));
});
</script>

<div class="contact-modal-overlay" style="display: none;">
  <div class="contact-modal-box">
    <div class="contact-modal-header">
      <span class="contact-modal-title"></span>
      <div class="header-actions">
        <button class="copy-button" data-email="yhy520@email.swu.edu.cn">
          <i class="fa fa-copy"></i>
        </button>
        <button class="contact-modal-close">&times;</button>
      </div>
    </div>
    <div class="contact-modal-body">
      <div class="image-wrapper">
        <img class="contact-qrcode" src="" alt="联系方式">
      </div>
    </div>
  </div>
</div>

<style>
/* 模态框基础样式 */
.contact-modal-overlay {
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  background: rgba(0,0,0,0.6);
  z-index: 9999;
  display: flex;
  justify-content: center;
  align-items: center;
  opacity: 0;
  transition: opacity 0.3s ease;
}

.contact-modal-box {
  background: #fff;
  border-radius: 12px;
  box-shadow: 0 5px 15px rgba(0,0,0,0.3);
  max-width: 80%;
  min-width: 300px;
  transform: scale(0.8);
  transition: all 0.3s ease;
}

.contact-modal-overlay.active {
  opacity: 1;
}

.contact-modal-overlay.active .contact-modal-box {
  transform: scale(1);
}

.contact-modal-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 15px 20px;
  border-bottom: 1px solid #eee;
}

.header-actions {
  display: flex;
  align-items: center;
  gap: 15px;
}

.contact-modal-title {
  font-size: 1.2em;
  color: #333;
  font-weight: bold;
}

.contact-modal-close {
  background: none;
  border: none;
  font-size: 24px;
  cursor: pointer;
  color: #666;
  transition: color 0.2s;
}

.contact-modal-close:hover {
  color: #333;
}

/* 图片容器 */
.image-wrapper {
  padding: 20px;
}

.contact-qrcode {
  max-width: 280px;
  max-height: 60vh;
  display: block;
  margin: 0 auto;
}

/* 复制按钮样式 */
.copy-button {
  background: rgba(255,255,255,0.9);
  border: 1px solid #eee;
  border-radius: 4px;
  padding: 6px 12px;
  cursor: pointer;
  transition: all 0.3s;
  display: none;
  color: #666;
}

.copy-button:hover {
  background: #fff;
  box-shadow: 0 2px 8px rgba(0,0,0,0.1);
}

/* 邮箱按钮颜色保护 */
a[href*="/images/email.png"] {
  color: #fff !important;
}

a[href*="/images/email.png"] i {
  color: inherit !important;
}

@media (max-width: 767px) {
  .contact-modal-box {
    max-width: 90%;
  }
  
  .contact-qrcode {
    max-width: 200px;
  }
  
  .header-actions {
    gap: 10px;
  }
  
  .copy-button {
    padding: 4px 8px;
  }
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
  // 绑定所有按钮事件
  const contactButtons = document.querySelectorAll(
    'a[href*="/images/wechat.png"], ' +
    'a[href*="/images/qq.png"], ' +
    'a[href*="/images/email.png"]'
  );

  // 通用展示函数
  const showContactModal = (type, path) => {
    const overlay = document.querySelector('.contact-modal-overlay');
    const title = document.querySelector('.contact-modal-title');
    const img = document.querySelector('.contact-qrcode');
    const copyBtn = document.querySelector('.copy-button');

    // 设置内容
    title.textContent = type;
    img.src = path;
    
    // 邮箱特殊处理
    if (type === '邮箱') {
      copyBtn.style.display = 'flex';
      copyBtn.querySelector('i').className = 'fa fa-copy'; // 重置图标状态
    } else {
      copyBtn.style.display = 'none';
    }

    // 显示模态框
    overlay.style.display = 'flex';
    setTimeout(() => overlay.classList.add('active'), 10);
  };

  // 绑定按钮点击事件
  contactButtons.forEach(btn => {
    btn.addEventListener('click', function(e) {
      e.preventDefault();
      const typeMap = {
        weixin: '微信',
        qq: 'QQ',
        envelope: '邮箱'
      };
      const iconClass = this.querySelector('i').className;
      const type = Object.keys(typeMap).find(key => iconClass.includes(key)) || '联系方式';
      showContactModal(typeMap[type], this.href);
    });
  });

  // 复制功能（防爬虫版）
  document.querySelector('.copy-button').addEventListener('click', function() {
    try {
      // 混淆邮箱地址（反转+Base64）
      const reversedEmail = 'yhy520@email.swu.edu.cn'.split('').reverse().join('');
      const realEmail = atob('eWh5NTIwQGVtYWlsLnN3dS5lZHUuY24='); // Base64解码
      
      navigator.clipboard.writeText(realEmail).then(() => {
        this.innerHTML = '<i class="fa fa-check"></i>';
        setTimeout(() => {
          this.innerHTML = '<i class="fa fa-copy"></i>';
        }, 2000);
      });
    } catch (error) {
      console.error('复制失败:', error);
      this.innerHTML = '<i class="fa fa-times"></i>';
      setTimeout(() => {
        this.innerHTML = '<i class="fa fa-copy"></i>';
      }, 2000);
    }
  });

  // 关闭逻辑
  const closeModal = () => {
    const overlay = document.querySelector('.contact-modal-overlay');
    overlay.classList.remove('active');
    setTimeout(() => {
      overlay.style.display = 'none';
    }, 300);
  };

  document.querySelector('.contact-modal-close').addEventListener('click', closeModal);
  document.querySelector('.contact-modal-overlay').addEventListener('click', (e) => {
    if(e.target === e.currentTarget) closeModal();
  });
});
</script>
</body>
</html>
